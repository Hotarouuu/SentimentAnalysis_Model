{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "02OaroZ-Lbj3"
      },
      "outputs": [],
      "source": [
        "# Importando bibliotecas\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from sentence_transformers import SentenceTransformer, util"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bSlUrGAO6Ds"
      },
      "source": [
        "## An√°lise de Dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Yk7xq89BMVJ3"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('training.1600000.processed.noemoticon.csv',\n",
        "                 encoding='latin-1',\n",
        "                 header=None,\n",
        "                 names=['target', 'ids', 'date', 'flag', 'user', 'text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "NnfjC1oWMYbS",
        "outputId": "83fd1d95-d929-4563-b16a-8387015404af"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>ids</th>\n",
              "      <th>date</th>\n",
              "      <th>flag</th>\n",
              "      <th>user</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810369</td>\n",
              "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>_TheSpecialOne_</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810672</td>\n",
              "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>scotthamilton</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810917</td>\n",
              "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>mattycus</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811184</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>ElleCTF</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811193</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>Karoli</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   target         ids                          date      flag  \\\n",
              "0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
              "1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
              "2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
              "3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
              "4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
              "\n",
              "              user                                               text  \n",
              "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
              "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
              "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
              "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
              "4           Karoli  @nationwideclass no, it's not behaving at all....  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "090vh__EMier",
        "outputId": "2bb476f1-f5dd-4f28-e0f9-94b2d457fb30"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "target     int64\n",
              "ids        int64\n",
              "date      object\n",
              "flag      object\n",
              "user      object\n",
              "text      object\n",
              "dtype: object"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWwOFwWNNM8t",
        "outputId": "9c483a56-02e3-480e-d8bd-8648ff3ee869"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Lucas\\AppData\\Local\\Temp\\ipykernel_19776\\3532345252.py:1: FutureWarning: Parsed string \"Mon Apr 06 22:19:45 PDT 2009\" included an un-recognized timezone \"PDT\". Dropping unrecognized timezones is deprecated; in a future version this will raise. Instead pass the string without the timezone, then use .tz_localize to convert to a recognized timezone.\n",
            "  df['date'] = pd.to_datetime(df['date'])\n"
          ]
        }
      ],
      "source": [
        "df['date'] = pd.to_datetime(df['date'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "neV79heaNRPR",
        "outputId": "f8c6ef8d-2f7a-445d-b7df-41b243862af1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>ids</th>\n",
              "      <th>date</th>\n",
              "      <th>flag</th>\n",
              "      <th>user</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810369</td>\n",
              "      <td>2009-04-06 22:19:45</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>_TheSpecialOne_</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810672</td>\n",
              "      <td>2009-04-06 22:19:49</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>scotthamilton</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810917</td>\n",
              "      <td>2009-04-06 22:19:53</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>mattycus</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811184</td>\n",
              "      <td>2009-04-06 22:19:57</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>ElleCTF</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811193</td>\n",
              "      <td>2009-04-06 22:19:57</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>Karoli</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   target         ids                date      flag             user  \\\n",
              "0       0  1467810369 2009-04-06 22:19:45  NO_QUERY  _TheSpecialOne_   \n",
              "1       0  1467810672 2009-04-06 22:19:49  NO_QUERY    scotthamilton   \n",
              "2       0  1467810917 2009-04-06 22:19:53  NO_QUERY         mattycus   \n",
              "3       0  1467811184 2009-04-06 22:19:57  NO_QUERY          ElleCTF   \n",
              "4       0  1467811193 2009-04-06 22:19:57  NO_QUERY           Karoli   \n",
              "\n",
              "                                                text  \n",
              "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
              "1  is upset that he can't update his Facebook by ...  \n",
              "2  @Kenichan I dived many times for the ball. Man...  \n",
              "3    my whole body feels itchy and like its on fire   \n",
              "4  @nationwideclass no, it's not behaving at all....  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZP3HoDFNZ57",
        "outputId": "89286b75-d804-4198-8c23-daf290ba149f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([2009])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['date'].dt.year.unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRQ89QENOsfY"
      },
      "source": [
        "Todos os tweets s√£o datados de 2009"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8eGzFytNm9c",
        "outputId": "c91c0401-ecbe-4c9c-adf4-71529aeec35c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 4], dtype=int64)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['target'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyEZVjFmNxgH"
      },
      "source": [
        "TARGET: the polarity of the tweet (0 = negative, 2 = neutral, 4 = positive)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aX0HjnWlNt3Y",
        "outputId": "720f997a-ea28-4060-fcef-6f1a11776e89"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1600000, 6)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6g2tSOAOxzf"
      },
      "source": [
        "DF com 1.6M de linhas e 6 colunas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRYVG-ydO3yj"
      },
      "source": [
        "## Tratamento de Dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "la1qXH6FOwWR"
      },
      "outputs": [],
      "source": [
        "df_treat = df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "oTYjJQ82PC1h",
        "outputId": "1eb45154-f8bd-4546-90f2-97057bcde7f8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>ids</th>\n",
              "      <th>date</th>\n",
              "      <th>flag</th>\n",
              "      <th>user</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810369</td>\n",
              "      <td>2009-04-06 22:19:45</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>_TheSpecialOne_</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810672</td>\n",
              "      <td>2009-04-06 22:19:49</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>scotthamilton</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810917</td>\n",
              "      <td>2009-04-06 22:19:53</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>mattycus</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811184</td>\n",
              "      <td>2009-04-06 22:19:57</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>ElleCTF</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811193</td>\n",
              "      <td>2009-04-06 22:19:57</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>Karoli</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   target         ids                date      flag             user  \\\n",
              "0       0  1467810369 2009-04-06 22:19:45  NO_QUERY  _TheSpecialOne_   \n",
              "1       0  1467810672 2009-04-06 22:19:49  NO_QUERY    scotthamilton   \n",
              "2       0  1467810917 2009-04-06 22:19:53  NO_QUERY         mattycus   \n",
              "3       0  1467811184 2009-04-06 22:19:57  NO_QUERY          ElleCTF   \n",
              "4       0  1467811193 2009-04-06 22:19:57  NO_QUERY           Karoli   \n",
              "\n",
              "                                                text  \n",
              "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
              "1  is upset that he can't update his Facebook by ...  \n",
              "2  @Kenichan I dived many times for the ball. Man...  \n",
              "3    my whole body feels itchy and like its on fire   \n",
              "4  @nationwideclass no, it's not behaving at all....  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_treat.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "5glGc9hqPDlV"
      },
      "outputs": [],
      "source": [
        "df_treat.drop(['date', 'flag', 'user'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "B8PmHUtTPL39",
        "outputId": "91ed8bb6-8080-4a52-d25e-29704eba9e3e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>ids</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810369</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810672</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810917</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811184</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811193</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599995</th>\n",
              "      <td>4</td>\n",
              "      <td>2193601966</td>\n",
              "      <td>Just woke up. Having no school is the best fee...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599996</th>\n",
              "      <td>4</td>\n",
              "      <td>2193601969</td>\n",
              "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599997</th>\n",
              "      <td>4</td>\n",
              "      <td>2193601991</td>\n",
              "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599998</th>\n",
              "      <td>4</td>\n",
              "      <td>2193602064</td>\n",
              "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599999</th>\n",
              "      <td>4</td>\n",
              "      <td>2193602129</td>\n",
              "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1600000 rows √ó 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         target         ids                                               text\n",
              "0             0  1467810369  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
              "1             0  1467810672  is upset that he can't update his Facebook by ...\n",
              "2             0  1467810917  @Kenichan I dived many times for the ball. Man...\n",
              "3             0  1467811184    my whole body feels itchy and like its on fire \n",
              "4             0  1467811193  @nationwideclass no, it's not behaving at all....\n",
              "...         ...         ...                                                ...\n",
              "1599995       4  2193601966  Just woke up. Having no school is the best fee...\n",
              "1599996       4  2193601969  TheWDB.com - Very cool to hear old Walt interv...\n",
              "1599997       4  2193601991  Are you ready for your MoJo Makeover? Ask me f...\n",
              "1599998       4  2193602064  Happy 38th Birthday to my boo of alll time!!! ...\n",
              "1599999       4  2193602129  happy #charitytuesday @theNSPCC @SparksCharity...\n",
              "\n",
              "[1600000 rows x 3 columns]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_treat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "df4 = df_treat[df_treat['target'] == 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>ids</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810369</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810672</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810917</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811184</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811193</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>799995</th>\n",
              "      <td>0</td>\n",
              "      <td>2329205009</td>\n",
              "      <td>Sick  Spending my day laying in bed listening ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>799996</th>\n",
              "      <td>0</td>\n",
              "      <td>2329205038</td>\n",
              "      <td>Gmail is down?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>799997</th>\n",
              "      <td>0</td>\n",
              "      <td>2329205473</td>\n",
              "      <td>rest in peace Farrah! So sad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>799998</th>\n",
              "      <td>0</td>\n",
              "      <td>2329205574</td>\n",
              "      <td>@Eric_Urbane Sounds like a rival is flagging y...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>799999</th>\n",
              "      <td>0</td>\n",
              "      <td>2329205794</td>\n",
              "      <td>has to resit exams over summer...  wishes he w...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>800000 rows √ó 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        target         ids                                               text\n",
              "0            0  1467810369  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
              "1            0  1467810672  is upset that he can't update his Facebook by ...\n",
              "2            0  1467810917  @Kenichan I dived many times for the ball. Man...\n",
              "3            0  1467811184    my whole body feels itchy and like its on fire \n",
              "4            0  1467811193  @nationwideclass no, it's not behaving at all....\n",
              "...        ...         ...                                                ...\n",
              "799995       0  2329205009  Sick  Spending my day laying in bed listening ...\n",
              "799996       0  2329205038                                    Gmail is down? \n",
              "799997       0  2329205473                      rest in peace Farrah! So sad \n",
              "799998       0  2329205574  @Eric_Urbane Sounds like a rival is flagging y...\n",
              "799999       0  2329205794  has to resit exams over summer...  wishes he w...\n",
              "\n",
              "[800000 rows x 3 columns]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHfl7zznPMg-",
        "outputId": "c2fdac8c-ee93-4eec-eb9e-73c0b0325abf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5 tweets para podermos tratar os dados: \n",
            "\n",
            "Tweet 0 ->  @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D \n",
            "\n",
            "Tweet 1 ->  is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah! \n",
            "\n",
            "Tweet 2 ->  @Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds \n",
            "\n",
            "Tweet 3 ->  my whole body feels itchy and like its on fire  \n",
            "\n",
            "Tweet 4 ->  @nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there.  \n",
            "\n",
            "Tweet 5 ->  @Kwesidei not the whole crew  \n",
            "\n"
          ]
        }
      ],
      "source": [
        "print('5 tweets para podermos tratar os dados: \\n')\n",
        "\n",
        "for i in range(0,6):\n",
        "  print(f'Tweet {i} -> ', df_treat['text'][i], '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "fHPmjPaoPR0D"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "\n",
        "def data_treat(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "\n",
        "    # Remove mentions and hashtags\n",
        "    text = re.sub(r'@\\w+|#\\w+', '', text)\n",
        "\n",
        "    # Remove punctuation and special characters\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "\n",
        "    # Remove extra whitespaces\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    return text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "wsUNLBcMQTJH"
      },
      "outputs": [],
      "source": [
        "dft = df[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46pYO837QWHK",
        "outputId": "ca374461-cdff-405e-de11-d06b73eadf09"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Lucas\\AppData\\Local\\Temp\\ipykernel_19776\\944507329.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  dft['text'] = dft['text'].apply(data_treat)\n"
          ]
        }
      ],
      "source": [
        "# Testando fun√ß√£o\n",
        "\n",
        "dft['text'] = dft['text'].apply(data_treat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "rnHWGZi_QXU8",
        "outputId": "055e6190-6f00-4b3d-cf1d-55142181ed0f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>ids</th>\n",
              "      <th>date</th>\n",
              "      <th>flag</th>\n",
              "      <th>user</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810369</td>\n",
              "      <td>2009-04-06 22:19:45</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>_TheSpecialOne_</td>\n",
              "      <td>a thats a bummer you shoulda got david carr of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810672</td>\n",
              "      <td>2009-04-06 22:19:49</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>scotthamilton</td>\n",
              "      <td>is upset that he cant update his facebook by t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810917</td>\n",
              "      <td>2009-04-06 22:19:53</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>mattycus</td>\n",
              "      <td>i dived many times for the ball managed to sav...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811184</td>\n",
              "      <td>2009-04-06 22:19:57</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>ElleCTF</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811193</td>\n",
              "      <td>2009-04-06 22:19:57</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>Karoli</td>\n",
              "      <td>no its not behaving at all im mad why am i her...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   target         ids                date      flag             user  \\\n",
              "0       0  1467810369 2009-04-06 22:19:45  NO_QUERY  _TheSpecialOne_   \n",
              "1       0  1467810672 2009-04-06 22:19:49  NO_QUERY    scotthamilton   \n",
              "2       0  1467810917 2009-04-06 22:19:53  NO_QUERY         mattycus   \n",
              "3       0  1467811184 2009-04-06 22:19:57  NO_QUERY          ElleCTF   \n",
              "4       0  1467811193 2009-04-06 22:19:57  NO_QUERY           Karoli   \n",
              "\n",
              "                                                text  \n",
              "0  a thats a bummer you shoulda got david carr of...  \n",
              "1  is upset that he cant update his facebook by t...  \n",
              "2  i dived many times for the ball managed to sav...  \n",
              "3     my whole body feels itchy and like its on fire  \n",
              "4  no its not behaving at all im mad why am i her...  "
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dft.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "OkRcygEvQ8qt"
      },
      "outputs": [],
      "source": [
        "df_treat['text'] = df_treat['text'].apply(data_treat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Ulgp6sYORk7r",
        "outputId": "cb93f0f3-c7e2-40f4-d854-61d47738e0eb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>ids</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810369</td>\n",
              "      <td>a thats a bummer you shoulda got david carr of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810672</td>\n",
              "      <td>is upset that he cant update his facebook by t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810917</td>\n",
              "      <td>i dived many times for the ball managed to sav...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811184</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811193</td>\n",
              "      <td>no its not behaving at all im mad why am i her...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599995</th>\n",
              "      <td>4</td>\n",
              "      <td>2193601966</td>\n",
              "      <td>just woke up having no school is the best feel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599996</th>\n",
              "      <td>4</td>\n",
              "      <td>2193601969</td>\n",
              "      <td>thewdbcom very cool to hear old walt interviews √¢</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599997</th>\n",
              "      <td>4</td>\n",
              "      <td>2193601991</td>\n",
              "      <td>are you ready for your mojo makeover ask me fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599998</th>\n",
              "      <td>4</td>\n",
              "      <td>2193602064</td>\n",
              "      <td>happy 38th birthday to my boo of alll time tup...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599999</th>\n",
              "      <td>4</td>\n",
              "      <td>2193602129</td>\n",
              "      <td>happy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1600000 rows √ó 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         target         ids                                               text\n",
              "0             0  1467810369  a thats a bummer you shoulda got david carr of...\n",
              "1             0  1467810672  is upset that he cant update his facebook by t...\n",
              "2             0  1467810917  i dived many times for the ball managed to sav...\n",
              "3             0  1467811184     my whole body feels itchy and like its on fire\n",
              "4             0  1467811193  no its not behaving at all im mad why am i her...\n",
              "...         ...         ...                                                ...\n",
              "1599995       4  2193601966  just woke up having no school is the best feel...\n",
              "1599996       4  2193601969  thewdbcom very cool to hear old walt interviews √¢\n",
              "1599997       4  2193601991  are you ready for your mojo makeover ask me fo...\n",
              "1599998       4  2193602064  happy 38th birthday to my boo of alll time tup...\n",
              "1599999       4  2193602129                                              happy\n",
              "\n",
              "[1600000 rows x 3 columns]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_treat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tamanho do treino: (100000, 3), Tamanho do teste: (50000, 3)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Selecionar 150.000 amostras do dataset original\n",
        "df_subset = df_treat.sample(n=150000, random_state=42)\n",
        "\n",
        "# Embaralhar e dividir o subset em treino e teste\n",
        "train_df, test_df = train_test_split(df_subset, test_size=50000, shuffle=True, random_state=42)\n",
        "\n",
        "train_df = train_df.reset_index(drop=True)\n",
        "test_df = test_df.reset_index(drop=True)\n",
        "\n",
        "# Verificar as dimens√µes\n",
        "print(f\"Tamanho do treino: {train_df.shape}, Tamanho do teste: {test_df.shape}\")\n",
        "\n",
        "# Agora, voc√™ pode continuar com a cria√ß√£o dos embeddings e DataLoaders\n",
        "train_embeddings = train_df['text'].values  # Pegando os embeddings de treino\n",
        "test_embeddings = test_df['text'].values  # Pegando os embeddings de teste\n",
        "\n",
        "# Codificando os alvos para valores inteiros\n",
        "le = LabelEncoder()\n",
        "\n",
        "train_embeddingsy = le.fit_transform(train_df['target'])  # Codificando as classes de treino\n",
        "test_embeddingsy = le.transform(test_df['target'])  # Codificando as classes de teste"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Come√ßando treinamento do Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_path = \"ibm-granite/granite-embedding-278m-multilingual\"\n",
        "# Load the Sentence Transformer model\n",
        "model = SentenceTransformer(model_path)\n",
        "\n",
        "# encode queries and passages\n",
        "train_embeddings = model.encode(train_embeddings)\n",
        "\n",
        "test_embeddings = model.encode(test_embeddings)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X shape: torch.Size([64, 768]), y shape: torch.Size([64])\n",
            "X shape: torch.Size([64, 768]), y shape: torch.Size([64])\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "\n",
        "# Certifique-se de que os dados est√£o no dispositivo certo\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Criando Dataset e DataLoader para os dados de teste\n",
        "X_test = torch.tensor(test_embeddings, dtype=torch.float32).to(device)\n",
        "y_test = torch.tensor(test_embeddingsy, dtype=torch.long).to(device)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Testar itera√ß√£o dos dados de teste\n",
        "for X, y in test_dataloader:\n",
        "    print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n",
        "    break  # Apenas para verificar um batch\n",
        "\n",
        "# Criando Dataset e DataLoader para os dados de treino\n",
        "X_train = torch.tensor(train_embeddings, dtype=torch.float32).to(device)\n",
        "y_train = torch.tensor(train_embeddingsy, dtype=torch.long).to(device)\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Testar itera√ß√£o dos dados de treino\n",
        "for X, y in train_dataloader:\n",
        "    print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n",
        "    break  # Apenas para verificar um batch\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0, 1, 1,  ..., 1, 0, 0], device='cuda:0')"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NeuralNetwork(\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=2, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Defini√ß√£o do modelo SYA3\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()  # Chama o construtor da classe pai (nn.Module)\n",
        "\n",
        "        # Pilha de camadas lineares com fun√ß√µes de ativa√ß√£o ReLU\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(768, 512),  # Camada totalmente conectada de entrada (768 -> 512 neur√¥nios)\n",
        "            nn.ReLU(),  # Fun√ß√£o de ativa√ß√£o ReLU para introduzir n√£o linearidade\n",
        "            nn.Linear(512, 512),  # Segunda camada oculta (512 -> 512 neur√¥nios)\n",
        "            nn.ReLU(),  # Ativa√ß√£o ReLU novamente\n",
        "            nn.Linear(512, 2),  # Camada de sa√≠da (512 -> 10 neur√¥nios, supondo 2 classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Define a passagem para frente (forward pass) do modelo\"\"\"\n",
        "        logits = self.linear_relu_stack(x)  # Passa os dados pela pilha de camadas\n",
        "        return logits  # Retorna os logits (valores brutos antes da ativa√ß√£o softmax)\n",
        "\n",
        "# Verifica se h√° uma GPU dispon√≠vel e define o dispositivo adequado (GPU ou CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Instancia o modelo e o move para o dispositivo correto (GPU se dispon√≠vel, sen√£o CPU)\n",
        "SentimentAnalysis_Model = NeuralNetwork().to(device)\n",
        "\n",
        "# Exibe a arquitetura do modelo\n",
        "print(SentimentAnalysis_Model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**O que √© a ReLU?**\n",
        "\n",
        "A ReLU (Rectified Linear Unit) √© uma fun√ß√£o de ativa√ß√£o amplamente usada em redes neurais. Ela √© respons√°vel por introduzir n√£o linearidade no modelo, permitindo que ele aprenda padr√µes mais complexos.\n",
        "\n",
        "A f√≥rmula da ReLU √© simples:\n",
        "\n",
        "    ReLU(x) = max(0, x)\n",
        "\n",
        "Ou seja:\n",
        "\n",
        "    Se o valor de entrada x for positivo, a sa√≠da ser√° x.\n",
        "    Se o valor de entrada x for negativo, a sa√≠da ser√° 0.\n",
        "\n",
        "**Por que usar a ReLU?**\n",
        "\n",
        "    Simples e eficiente: A ReLU √© muito simples de calcular, o que ajuda a tornar o treinamento mais r√°pido.\n",
        "    Evita o problema do gradiente desvanecido: Quando voc√™ usa fun√ß√µes como sigmoid ou tanh, elas podem \"saturar\" (ficar muito pr√≥ximas de 0 ou 1), fazendo com que o gradiente durante o treinamento diminua muito (desvanecimento do gradiente). A ReLU resolve esse problema, pois para valores positivos, ela retorna uma inclina√ß√£o constante.\n",
        "    Efetiva em muitas tarefas: A ReLU tem sido usada com sucesso em uma vasta gama de modelos de deep learning.\n",
        "\n",
        "Exemplo:\n",
        "\n",
        "Se tivermos uma entrada x = -2, a ReLU retorna 0. Se a entrada for x = 3, a sa√≠da ser√° 3.\n",
        "\n",
        "**O que √© \"n√£o linearidade\" e por que √© importante?**\n",
        "\n",
        "N√£o linearidade √© a capacidade de um modelo aprender rela√ß√µes complexas entre as entradas e sa√≠das.\n",
        "Se us√°ssemos apenas opera√ß√µes lineares (por exemplo, multiplica√ß√µes e somas), o modelo seria equivalente a uma √∫nica transforma√ß√£o linear, n√£o importando quantas camadas tiv√©ssemos. Isso limitaria sua capacidade de modelar padr√µes complexos.\n",
        "\n",
        "    Ao aplicar fun√ß√µes de ativa√ß√£o n√£o lineares, como a ReLU, o modelo pode combinar essas transforma√ß√µes lineares de forma a capturar rela√ß√µes complexas.\n",
        "    Exemplo: Imagine que voc√™ precisa modelar uma rela√ß√£o curva entre vari√°veis. Uma simples combina√ß√£o linear n√£o consegue representar essa curva. Com fun√ß√µes n√£o lineares, o modelo pode aprender essa curvatura e outros padr√µes complexos presentes nos dados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(SentimentAnalysis_Model.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "**Fun√ß√£o de Perda**\n",
        "\n",
        "A fun√ß√£o de perda √© uma fun√ß√£o matem√°tica que mede o erro do modelo durante o treinamento. O objetivo do treinamento √© minimizar esse erro, ou seja, fazer com que o modelo preveja o mais pr√≥ximo poss√≠vel da verdade real.\n",
        "\n",
        "No seu caso, voc√™ est√° usando a fun√ß√£o de perda CrossEntropyLoss.\n",
        "\n",
        "CrossEntropyLoss √© usada em problemas de classifica√ß√£o, onde o modelo precisa escolher entre v√°rias classes poss√≠veis (por exemplo, identificar qual √© a imagem de um gato, cachorro, etc.).\n",
        "\n",
        "A fun√ß√£o CrossEntropyLoss compara as probabilidades previstas pelo modelo com as probabilidades reais e calcula um valor de erro. Quanto menor o valor da perda, melhor o modelo est√° se saindo.\n",
        "Como a CrossEntropyLoss funciona:\n",
        "\n",
        "    O modelo gera uma probabilidade para cada classe. Se temos 3 classes, o modelo pode prever algo como: [0.2, 0.7, 0.1].\n",
        "    Se a classe real for a classe 2 (index 1), a CrossEntropyLoss vai penalizar o modelo mais fortemente quanto menor for a probabilidade atribu√≠da √† classe correta.\n",
        "\n",
        "**Otimizador**\n",
        "\n",
        "O otimizador √© o componente que ajusta os pesos do modelo para reduzir a fun√ß√£o de perda. Ele basicamente determina como os par√¢metros do modelo (os pesos das conex√µes entre os neur√¥nios) devem ser atualizados para reduzir o erro.\n",
        "\n",
        "Aqui estamos usando o SGD (Stochastic Gradient Descent) como otimizador.\n",
        "\n",
        "O que √© o SGD?\n",
        "\n",
        "O SGD √© uma vers√£o do gradiente descendente onde a atualiza√ß√£o dos pesos √© feita com base em apenas um exemplo (ou poucos exemplos) de cada vez, ao inv√©s de usar todos os exemplos no conjunto de dados. Isso torna o processo de otimiza√ß√£o mais r√°pido, embora possa ser um pouco mais ruidoso.\n",
        "Como o SGD funciona:\n",
        "\n",
        "    Calcula o Gradiente: O SGD calcula a dire√ß√£o do gradiente da fun√ß√£o de perda em rela√ß√£o aos par√¢metros do modelo (como os pesos). O gradiente indica em que dire√ß√£o devemos ajustar os par√¢metros para reduzir a perda.\n",
        "    Atualiza os Pesos: O SGD usa a dire√ß√£o do gradiente para atualizar os par√¢metros. A atualiza√ß√£o √© feita com base em uma taxa chamada taxa de aprendizado (learning rate).\n",
        "        Se a taxa de aprendizado for alta, os pesos ser√£o ajustados em grandes passos.\n",
        "        Se for baixa, o ajuste ser√° mais sutil.\n",
        "\n",
        "A f√≥rmula para o gradiente descendente simples √©:\n",
        "\n",
        "    w = w - lr * gradiente, onde:\n",
        "        w s√£o os pesos do modelo,\n",
        "        lr √© a taxa de aprendizado,\n",
        "        gradiente √© a derivada da fun√ß√£o de perda em rela√ß√£o aos pesos.\n",
        "\n",
        "Par√¢metros do Otimizador:\n",
        "\n",
        "    model.parameters(): Passa todos os par√¢metros do modelo (os pesos e vieses dos neur√¥nios) para o otimizador, para que ele possa atualiz√°-los durante o treinamento.\n",
        "    lr=1e-3: A taxa de aprendizado, que controla o tamanho dos passos dados durante a atualiza√ß√£o dos pesos. 1e-3 √© o mesmo que 0.001. Se a taxa de aprendizado for muito alta, o modelo pode \"pular\" a solu√ß√£o √≥tima. Se for muito baixa, o treinamento ser√° mais demorado.\n",
        "\n",
        "Resumo:\n",
        "\n",
        "    Fun√ß√£o de Perda (como CrossEntropyLoss) mede o erro entre as previs√µes do modelo e as classes reais. O objetivo √© minimizar essa perda.\n",
        "    Otimizador (como SGD) atualiza os pesos do modelo para reduzir a perda, ajustando-os com base no gradiente da fun√ß√£o de perda.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset) # Calcula o tamanho do dataset de treino\n",
        "    model.train() # Treina o modelo\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error -> Preve o resultado e calcula  fun√ß√£o de perda\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation -> Otimizador usa a fun√ß√£o de perda para ajustar o modelo e ao mesmo tempo minimizar a fun√ß√£o de perda\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), (batch + 1) * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset) # Calcula o tamanho do dataset de teste\n",
        "    num_batches = len(dataloader) # Calcula a quantidade de batchs (quantidade de dados que ser√£o processados por vez)\n",
        "    model.eval() # Avalia√ß√£o do modelo\n",
        "    test_loss, correct = 0, 0  # Inicializa as vari√°veis para armazenar a perda total (test_loss) e o n√∫mero de acertos (correct) com zero\n",
        "    with torch.no_grad():  # Desativa o c√°lculo de gradientes para economizar mem√≥ria e tempo de computa√ß√£o\n",
        "        for X, y in dataloader:  # Itera sobre o DataLoader, que fornece batches de dados de entrada (X) e r√≥tulos reais (y)\n",
        "            X, y = X.to(device), y.to(device)  # Move os dados e r√≥tulos para o dispositivo (CPU ou GPU)\n",
        "            pred = model(X)  # Faz uma previs√£o usando o modelo com os dados de entrada X\n",
        "            test_loss += loss_fn(pred, y).item()  # Calcula a perda entre a previs√£o e o r√≥tulo real, adicionando ao total da perda\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()  # Conta as previs√µes corretas (compara a classe com maior probabilidade)\n",
        "    test_loss /= num_batches  # Calcula a m√©dia da perda no conjunto de teste\n",
        "    correct /= size  # Calcula a acur√°cia dividindo o n√∫mero de acertos pelo total de amostras\n",
        "\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "\n",
            "Training: \n",
            "\n",
            "loss: 0.691761  [   64/100000]\n",
            "loss: 0.690514  [ 6464/100000]\n",
            "loss: 0.694211  [12864/100000]\n",
            "loss: 0.689152  [19264/100000]\n",
            "loss: 0.693704  [25664/100000]\n",
            "loss: 0.692391  [32064/100000]\n",
            "loss: 0.689284  [38464/100000]\n",
            "loss: 0.693021  [44864/100000]\n",
            "loss: 0.691416  [51264/100000]\n",
            "loss: 0.693556  [57664/100000]\n",
            "loss: 0.693695  [64064/100000]\n",
            "loss: 0.693706  [70464/100000]\n",
            "loss: 0.691678  [76864/100000]\n",
            "loss: 0.692293  [83264/100000]\n",
            "loss: 0.692623  [89664/100000]\n",
            "loss: 0.691928  [96064/100000]\n",
            "\n",
            "Testing: \n",
            "\n",
            "Test Error: \n",
            " Accuracy: 50.2%, Avg loss: 0.692970 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "\n",
            "Training: \n",
            "\n",
            "loss: 0.693437  [   64/100000]\n",
            "loss: 0.693887  [ 6464/100000]\n",
            "loss: 0.691819  [12864/100000]\n",
            "loss: 0.695604  [19264/100000]\n",
            "loss: 0.693179  [25664/100000]\n",
            "loss: 0.692986  [32064/100000]\n",
            "loss: 0.693434  [38464/100000]\n",
            "loss: 0.693924  [44864/100000]\n",
            "loss: 0.692936  [51264/100000]\n",
            "loss: 0.693187  [57664/100000]\n",
            "loss: 0.691977  [64064/100000]\n",
            "loss: 0.692867  [70464/100000]\n",
            "loss: 0.693176  [76864/100000]\n",
            "loss: 0.693456  [83264/100000]\n",
            "loss: 0.692852  [89664/100000]\n",
            "loss: 0.692274  [96064/100000]\n",
            "\n",
            "Testing: \n",
            "\n",
            "Test Error: \n",
            " Accuracy: 51.7%, Avg loss: 0.692795 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "\n",
            "Training: \n",
            "\n",
            "loss: 0.692318  [   64/100000]\n",
            "loss: 0.692417  [ 6464/100000]\n",
            "loss: 0.693205  [12864/100000]\n",
            "loss: 0.692429  [19264/100000]\n",
            "loss: 0.692412  [25664/100000]\n",
            "loss: 0.693464  [32064/100000]\n",
            "loss: 0.692860  [38464/100000]\n",
            "loss: 0.692899  [44864/100000]\n",
            "loss: 0.692286  [51264/100000]\n",
            "loss: 0.692911  [57664/100000]\n",
            "loss: 0.692552  [64064/100000]\n",
            "loss: 0.693003  [70464/100000]\n",
            "loss: 0.691955  [76864/100000]\n",
            "loss: 0.692621  [83264/100000]\n",
            "loss: 0.693059  [89664/100000]\n",
            "loss: 0.693194  [96064/100000]\n",
            "\n",
            "Testing: \n",
            "\n",
            "Test Error: \n",
            " Accuracy: 53.8%, Avg loss: 0.692627 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "\n",
            "Training: \n",
            "\n",
            "loss: 0.693547  [   64/100000]\n",
            "loss: 0.692346  [ 6464/100000]\n",
            "loss: 0.692991  [12864/100000]\n",
            "loss: 0.692636  [19264/100000]\n",
            "loss: 0.692246  [25664/100000]\n",
            "loss: 0.692560  [32064/100000]\n",
            "loss: 0.693038  [38464/100000]\n",
            "loss: 0.692786  [44864/100000]\n",
            "loss: 0.691955  [51264/100000]\n",
            "loss: 0.692516  [57664/100000]\n",
            "loss: 0.692966  [64064/100000]\n",
            "loss: 0.692498  [70464/100000]\n",
            "loss: 0.693079  [76864/100000]\n",
            "loss: 0.691841  [83264/100000]\n",
            "loss: 0.691782  [89664/100000]\n",
            "loss: 0.693184  [96064/100000]\n",
            "\n",
            "Testing: \n",
            "\n",
            "Test Error: \n",
            " Accuracy: 55.6%, Avg loss: 0.692456 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "\n",
            "Training: \n",
            "\n",
            "loss: 0.692585  [   64/100000]\n",
            "loss: 0.692186  [ 6464/100000]\n",
            "loss: 0.692790  [12864/100000]\n",
            "loss: 0.692579  [19264/100000]\n",
            "loss: 0.693034  [25664/100000]\n",
            "loss: 0.691985  [32064/100000]\n",
            "loss: 0.692631  [38464/100000]\n",
            "loss: 0.691786  [44864/100000]\n",
            "loss: 0.691996  [51264/100000]\n",
            "loss: 0.693709  [57664/100000]\n",
            "loss: 0.691997  [64064/100000]\n",
            "loss: 0.692574  [70464/100000]\n",
            "loss: 0.692790  [76864/100000]\n",
            "loss: 0.691873  [83264/100000]\n",
            "loss: 0.692536  [89664/100000]\n",
            "loss: 0.692177  [96064/100000]\n",
            "\n",
            "Testing: \n",
            "\n",
            "Test Error: \n",
            " Accuracy: 61.0%, Avg loss: 0.692282 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "\n",
            "Training: \n",
            "\n",
            "loss: 0.692401  [   64/100000]\n",
            "loss: 0.691987  [ 6464/100000]\n",
            "loss: 0.692567  [12864/100000]\n",
            "loss: 0.692933  [19264/100000]\n",
            "loss: 0.693038  [25664/100000]\n",
            "loss: 0.692278  [32064/100000]\n",
            "loss: 0.691425  [38464/100000]\n",
            "loss: 0.692237  [44864/100000]\n",
            "loss: 0.692382  [51264/100000]\n",
            "loss: 0.692288  [57664/100000]\n",
            "loss: 0.692258  [64064/100000]\n",
            "loss: 0.692050  [70464/100000]\n",
            "loss: 0.692116  [76864/100000]\n",
            "loss: 0.692613  [83264/100000]\n",
            "loss: 0.692448  [89664/100000]\n",
            "loss: 0.692083  [96064/100000]\n",
            "\n",
            "Testing: \n",
            "\n",
            "Test Error: \n",
            " Accuracy: 61.0%, Avg loss: 0.692099 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "\n",
            "Training: \n",
            "\n",
            "loss: 0.691967  [   64/100000]\n",
            "loss: 0.691799  [ 6464/100000]\n",
            "loss: 0.692601  [12864/100000]\n",
            "loss: 0.691846  [19264/100000]\n",
            "loss: 0.691471  [25664/100000]\n",
            "loss: 0.692068  [32064/100000]\n",
            "loss: 0.692190  [38464/100000]\n",
            "loss: 0.691574  [44864/100000]\n",
            "loss: 0.692266  [51264/100000]\n",
            "loss: 0.692333  [57664/100000]\n",
            "loss: 0.691882  [64064/100000]\n",
            "loss: 0.691515  [70464/100000]\n",
            "loss: 0.692500  [76864/100000]\n",
            "loss: 0.692315  [83264/100000]\n",
            "loss: 0.691955  [89664/100000]\n",
            "loss: 0.692750  [96064/100000]\n",
            "\n",
            "Testing: \n",
            "\n",
            "Test Error: \n",
            " Accuracy: 64.2%, Avg loss: 0.691905 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "\n",
            "Training: \n",
            "\n",
            "loss: 0.691682  [   64/100000]\n",
            "loss: 0.691615  [ 6464/100000]\n",
            "loss: 0.692122  [12864/100000]\n",
            "loss: 0.691568  [19264/100000]\n",
            "loss: 0.691931  [25664/100000]\n",
            "loss: 0.692217  [32064/100000]\n",
            "loss: 0.690983  [38464/100000]\n",
            "loss: 0.692128  [44864/100000]\n",
            "loss: 0.691147  [51264/100000]\n",
            "loss: 0.692596  [57664/100000]\n",
            "loss: 0.692233  [64064/100000]\n",
            "loss: 0.691459  [70464/100000]\n",
            "loss: 0.691854  [76864/100000]\n",
            "loss: 0.692068  [83264/100000]\n",
            "loss: 0.692210  [89664/100000]\n",
            "loss: 0.691434  [96064/100000]\n",
            "\n",
            "Testing: \n",
            "\n",
            "Test Error: \n",
            " Accuracy: 68.4%, Avg loss: 0.691700 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "\n",
            "Training: \n",
            "\n",
            "loss: 0.691748  [   64/100000]\n",
            "loss: 0.691457  [ 6464/100000]\n",
            "loss: 0.691928  [12864/100000]\n",
            "loss: 0.692147  [19264/100000]\n",
            "loss: 0.691304  [25664/100000]\n",
            "loss: 0.692261  [32064/100000]\n",
            "loss: 0.692082  [38464/100000]\n",
            "loss: 0.691323  [44864/100000]\n",
            "loss: 0.691309  [51264/100000]\n",
            "loss: 0.691709  [57664/100000]\n",
            "loss: 0.691302  [64064/100000]\n",
            "loss: 0.691507  [70464/100000]\n",
            "loss: 0.691691  [76864/100000]\n",
            "loss: 0.691895  [83264/100000]\n",
            "loss: 0.691606  [89664/100000]\n",
            "loss: 0.691979  [96064/100000]\n",
            "\n",
            "Testing: \n",
            "\n",
            "Test Error: \n",
            " Accuracy: 70.9%, Avg loss: 0.691481 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "\n",
            "Training: \n",
            "\n",
            "loss: 0.691511  [   64/100000]\n",
            "loss: 0.690834  [ 6464/100000]\n",
            "loss: 0.691369  [12864/100000]\n",
            "loss: 0.691778  [19264/100000]\n",
            "loss: 0.690824  [25664/100000]\n",
            "loss: 0.690979  [32064/100000]\n",
            "loss: 0.691838  [38464/100000]\n",
            "loss: 0.691027  [44864/100000]\n",
            "loss: 0.690514  [51264/100000]\n",
            "loss: 0.691953  [57664/100000]\n",
            "loss: 0.690874  [64064/100000]\n",
            "loss: 0.691533  [70464/100000]\n",
            "loss: 0.691582  [76864/100000]\n",
            "loss: 0.690710  [83264/100000]\n",
            "loss: 0.690799  [89664/100000]\n",
            "loss: 0.690838  [96064/100000]\n",
            "\n",
            "Testing: \n",
            "\n",
            "Test Error: \n",
            " Accuracy: 70.1%, Avg loss: 0.691239 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "\n",
            "Training: \n",
            "\n",
            "loss: 0.691225  [   64/100000]\n",
            "loss: 0.691792  [ 6464/100000]\n",
            "loss: 0.691169  [12864/100000]\n",
            "loss: 0.691178  [19264/100000]\n",
            "loss: 0.690680  [25664/100000]\n",
            "loss: 0.690209  [32064/100000]\n",
            "loss: 0.691260  [38464/100000]\n",
            "loss: 0.691576  [44864/100000]\n",
            "loss: 0.690955  [51264/100000]\n",
            "loss: 0.691953  [57664/100000]\n",
            "loss: 0.691496  [64064/100000]\n",
            "loss: 0.690918  [70464/100000]\n",
            "loss: 0.691694  [76864/100000]\n",
            "loss: 0.690279  [83264/100000]\n",
            "loss: 0.691336  [89664/100000]\n",
            "loss: 0.690749  [96064/100000]\n",
            "\n",
            "Testing: \n",
            "\n",
            "Test Error: \n",
            " Accuracy: 69.6%, Avg loss: 0.690979 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "\n",
            "Training: \n",
            "\n",
            "loss: 0.692312  [   64/100000]\n",
            "loss: 0.690148  [ 6464/100000]\n",
            "loss: 0.690776  [12864/100000]\n",
            "loss: 0.690395  [19264/100000]\n",
            "loss: 0.691700  [25664/100000]\n",
            "loss: 0.691258  [32064/100000]\n",
            "loss: 0.690469  [38464/100000]\n",
            "loss: 0.691289  [44864/100000]\n",
            "loss: 0.690955  [51264/100000]\n",
            "loss: 0.691944  [57664/100000]\n",
            "loss: 0.691511  [64064/100000]\n",
            "loss: 0.692180  [70464/100000]\n",
            "loss: 0.689840  [76864/100000]\n",
            "loss: 0.690488  [83264/100000]\n",
            "loss: 0.690020  [89664/100000]\n",
            "loss: 0.690575  [96064/100000]\n",
            "\n",
            "Testing: \n",
            "\n",
            "Test Error: \n",
            " Accuracy: 71.8%, Avg loss: 0.690706 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "\n",
            "Training: \n",
            "\n",
            "loss: 0.689792  [   64/100000]\n",
            "loss: 0.690971  [ 6464/100000]\n",
            "loss: 0.690885  [12864/100000]\n",
            "loss: 0.690932  [19264/100000]\n",
            "loss: 0.690760  [25664/100000]\n",
            "loss: 0.690897  [32064/100000]\n",
            "loss: 0.691500  [38464/100000]\n",
            "loss: 0.691044  [44864/100000]\n",
            "loss: 0.690484  [51264/100000]\n",
            "loss: 0.690820  [57664/100000]\n",
            "loss: 0.690591  [64064/100000]\n",
            "loss: 0.690815  [70464/100000]\n",
            "loss: 0.689614  [76864/100000]\n",
            "loss: 0.689146  [83264/100000]\n",
            "loss: 0.690904  [89664/100000]\n",
            "loss: 0.691218  [96064/100000]\n",
            "\n",
            "Testing: \n",
            "\n",
            "Test Error: \n",
            " Accuracy: 72.3%, Avg loss: 0.690401 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "\n",
            "Training: \n",
            "\n",
            "loss: 0.690680  [   64/100000]\n",
            "loss: 0.690778  [ 6464/100000]\n",
            "loss: 0.690894  [12864/100000]\n",
            "loss: 0.689875  [19264/100000]\n",
            "loss: 0.690044  [25664/100000]\n",
            "loss: 0.689923  [32064/100000]\n",
            "loss: 0.690331  [38464/100000]\n",
            "loss: 0.690126  [44864/100000]\n",
            "loss: 0.689239  [51264/100000]\n",
            "loss: 0.689650  [57664/100000]\n",
            "loss: 0.690999  [64064/100000]\n",
            "loss: 0.689800  [70464/100000]\n",
            "loss: 0.691118  [76864/100000]\n",
            "loss: 0.689373  [83264/100000]\n",
            "loss: 0.689733  [89664/100000]\n",
            "loss: 0.691043  [96064/100000]\n",
            "\n",
            "Testing: \n",
            "\n",
            "Test Error: \n",
            " Accuracy: 70.9%, Avg loss: 0.690065 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "\n",
            "Training: \n",
            "\n",
            "loss: 0.690034  [   64/100000]\n",
            "loss: 0.688704  [ 6464/100000]\n",
            "loss: 0.689506  [12864/100000]\n",
            "loss: 0.689733  [19264/100000]\n",
            "loss: 0.690772  [25664/100000]\n",
            "loss: 0.689809  [32064/100000]\n",
            "loss: 0.690522  [38464/100000]\n",
            "loss: 0.689359  [44864/100000]\n",
            "loss: 0.690038  [51264/100000]\n",
            "loss: 0.690716  [57664/100000]\n",
            "loss: 0.689584  [64064/100000]\n",
            "loss: 0.690043  [70464/100000]\n",
            "loss: 0.690025  [76864/100000]\n",
            "loss: 0.689287  [83264/100000]\n",
            "loss: 0.690075  [89664/100000]\n",
            "loss: 0.689457  [96064/100000]\n",
            "\n",
            "Testing: \n",
            "\n",
            "Test Error: \n",
            " Accuracy: 72.5%, Avg loss: 0.689701 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "\n",
            "Training: \n",
            "\n",
            "loss: 0.690566  [   64/100000]\n",
            "loss: 0.690786  [ 6464/100000]\n",
            "loss: 0.689231  [12864/100000]\n",
            "loss: 0.690676  [19264/100000]\n",
            "loss: 0.689734  [25664/100000]\n",
            "loss: 0.690374  [32064/100000]\n",
            "loss: 0.689848  [38464/100000]\n",
            "loss: 0.689052  [44864/100000]\n",
            "loss: 0.689617  [51264/100000]\n",
            "loss: 0.688682  [57664/100000]\n",
            "loss: 0.690320  [64064/100000]\n",
            "loss: 0.689661  [70464/100000]\n",
            "loss: 0.688598  [76864/100000]\n",
            "loss: 0.688549  [83264/100000]\n",
            "loss: 0.689898  [89664/100000]\n",
            "loss: 0.689493  [96064/100000]\n",
            "\n",
            "Testing: \n",
            "\n",
            "Test Error: \n",
            " Accuracy: 72.4%, Avg loss: 0.689293 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "\n",
            "Training: \n",
            "\n",
            "loss: 0.688925  [   64/100000]\n",
            "loss: 0.688965  [ 6464/100000]\n",
            "loss: 0.688983  [12864/100000]\n",
            "loss: 0.687934  [19264/100000]\n",
            "loss: 0.689795  [25664/100000]\n",
            "loss: 0.690274  [32064/100000]\n",
            "loss: 0.690278  [38464/100000]\n",
            "loss: 0.688649  [44864/100000]\n",
            "loss: 0.690001  [51264/100000]\n",
            "loss: 0.689864  [57664/100000]\n",
            "loss: 0.689172  [64064/100000]\n",
            "loss: 0.690800  [70464/100000]\n",
            "loss: 0.688519  [76864/100000]\n",
            "loss: 0.689961  [83264/100000]\n",
            "loss: 0.688274  [89664/100000]\n",
            "loss: 0.688562  [96064/100000]\n",
            "\n",
            "Testing: \n",
            "\n",
            "Test Error: \n",
            " Accuracy: 72.2%, Avg loss: 0.688837 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "\n",
            "Training: \n",
            "\n",
            "loss: 0.689181  [   64/100000]\n",
            "loss: 0.688332  [ 6464/100000]\n",
            "loss: 0.688537  [12864/100000]\n",
            "loss: 0.689110  [19264/100000]\n",
            "loss: 0.688678  [25664/100000]\n",
            "loss: 0.690293  [32064/100000]\n",
            "loss: 0.688245  [38464/100000]\n",
            "loss: 0.690018  [44864/100000]\n",
            "loss: 0.688534  [51264/100000]\n",
            "loss: 0.689116  [57664/100000]\n",
            "loss: 0.688523  [64064/100000]\n",
            "loss: 0.688763  [70464/100000]\n",
            "loss: 0.690478  [76864/100000]\n",
            "loss: 0.689324  [83264/100000]\n",
            "loss: 0.687822  [89664/100000]\n",
            "loss: 0.689960  [96064/100000]\n",
            "\n",
            "Testing: \n",
            "\n",
            "Test Error: \n",
            " Accuracy: 71.2%, Avg loss: 0.688325 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "\n",
            "Training: \n",
            "\n",
            "loss: 0.688204  [   64/100000]\n",
            "loss: 0.687272  [ 6464/100000]\n",
            "loss: 0.687488  [12864/100000]\n",
            "loss: 0.689706  [19264/100000]\n",
            "loss: 0.688628  [25664/100000]\n",
            "loss: 0.686993  [32064/100000]\n",
            "loss: 0.686933  [38464/100000]\n",
            "loss: 0.688402  [44864/100000]\n",
            "loss: 0.688401  [51264/100000]\n",
            "loss: 0.687810  [57664/100000]\n",
            "loss: 0.686374  [64064/100000]\n",
            "loss: 0.687288  [70464/100000]\n",
            "loss: 0.685399  [76864/100000]\n",
            "loss: 0.688653  [83264/100000]\n",
            "loss: 0.686439  [89664/100000]\n",
            "loss: 0.687186  [96064/100000]\n",
            "\n",
            "Testing: \n",
            "\n",
            "Test Error: \n",
            " Accuracy: 72.9%, Avg loss: 0.687750 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "\n",
            "Training: \n",
            "\n",
            "loss: 0.688290  [   64/100000]\n",
            "loss: 0.688837  [ 6464/100000]\n",
            "loss: 0.688480  [12864/100000]\n",
            "loss: 0.687628  [19264/100000]\n",
            "loss: 0.685199  [25664/100000]\n",
            "loss: 0.687216  [32064/100000]\n",
            "loss: 0.687343  [38464/100000]\n",
            "loss: 0.688680  [44864/100000]\n",
            "loss: 0.687558  [51264/100000]\n",
            "loss: 0.687480  [57664/100000]\n",
            "loss: 0.685457  [64064/100000]\n",
            "loss: 0.686140  [70464/100000]\n",
            "loss: 0.687008  [76864/100000]\n",
            "loss: 0.687571  [83264/100000]\n",
            "loss: 0.687080  [89664/100000]\n",
            "loss: 0.688597  [96064/100000]\n",
            "\n",
            "Testing: \n",
            "\n",
            "Test Error: \n",
            " Accuracy: 73.0%, Avg loss: 0.687096 \n",
            "\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "epochs = 20\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    print(f'\\nTraining: \\n')\n",
        "    train(train_dataloader, SentimentAnalysis_Model, loss_fn, optimizer)\n",
        "    print(f'\\nTesting: \\n')\n",
        "\n",
        "    test(test_dataloader, SentimentAnalysis_Model, loss_fn)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Texto: I  hate MY LIFE EVERYDAY\n",
            "Texto negativo\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def programa(texto):\n",
        "    # Carregar o modelo de embeddings (SentenceTransformer)\n",
        "\n",
        "    # Cria uma lista com o texto a ser processado\n",
        "    novos_textos = [texto]\n",
        "\n",
        "    # Gera os embeddings dos textos (retorna um numpy array)\n",
        "    novos_embeddings = model.encode(novos_textos)\n",
        "\n",
        "    # Converte os embeddings para tensor e os move para o dispositivo\n",
        "    novos_embeddings_tensor = torch.tensor(novos_embeddings, dtype=torch.float32).to(device)\n",
        "\n",
        "    # Coloca o modelo de classifica√ß√£o em modo de avalia√ß√£o\n",
        "    SentimentAnalysis_Model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Passa os embeddings pelo modelo de classifica√ß√£o\n",
        "        outputs = SentimentAnalysis_Model(novos_embeddings_tensor)\n",
        "        # Se o modelo √© de classifica√ß√£o, obtenha a classe prevista\n",
        "        _, predicted_classes = torch.max(outputs, dim=1)\n",
        "        predicted_label = le.inverse_transform(predicted_classes.cpu().numpy())\n",
        "\n",
        "    print(f\"Texto: {texto}\")\n",
        "    #print(f\"Embeddings gerados: {novos_embeddings_tensor}\")\n",
        "    if predicted_label == 4:\n",
        "        \n",
        "       #print(f\"Classe prevista: {predicted_label.item()}\")\n",
        "       print(f'Texto positivo!')\n",
        "    else:\n",
        "        print(f'Texto negativo')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Texto: I love my life\n",
            "Texto positivo!\n"
          ]
        }
      ],
      "source": [
        "text = input('Escreva sua mensagem: ')\n",
        "programa(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved PyTorch Model State to model.pth\n"
          ]
        }
      ],
      "source": [
        "torch.save(SentimentAnalysis_Model.state_dict(), \"SentimentAnalysis_Model.pth\")\n",
        "print(\"Saved PyTorch Model State to model.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
