{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "02OaroZ-Lbj3"
      },
      "outputs": [],
      "source": [
        "# Importando bibliotecas\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from sentence_transformers import SentenceTransformer, util"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bSlUrGAO6Ds"
      },
      "source": [
        "## Análise de Dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Yk7xq89BMVJ3"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('training.1600000.processed.noemoticon.csv',\n",
        "                 encoding='latin-1',\n",
        "                 header=None,\n",
        "                 names=['target', 'ids', 'date', 'flag', 'user', 'text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "NnfjC1oWMYbS",
        "outputId": "83fd1d95-d929-4563-b16a-8387015404af"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>ids</th>\n",
              "      <th>date</th>\n",
              "      <th>flag</th>\n",
              "      <th>user</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810369</td>\n",
              "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>_TheSpecialOne_</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810672</td>\n",
              "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>scotthamilton</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810917</td>\n",
              "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>mattycus</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811184</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>ElleCTF</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811193</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>Karoli</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   target         ids                          date      flag  \\\n",
              "0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
              "1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
              "2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
              "3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
              "4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
              "\n",
              "              user                                               text  \n",
              "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
              "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
              "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
              "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
              "4           Karoli  @nationwideclass no, it's not behaving at all....  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "090vh__EMier",
        "outputId": "2bb476f1-f5dd-4f28-e0f9-94b2d457fb30"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "target     int64\n",
              "ids        int64\n",
              "date      object\n",
              "flag      object\n",
              "user      object\n",
              "text      object\n",
              "dtype: object"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWwOFwWNNM8t",
        "outputId": "9c483a56-02e3-480e-d8bd-8648ff3ee869"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Lucas\\AppData\\Local\\Temp\\ipykernel_19776\\3532345252.py:1: FutureWarning: Parsed string \"Mon Apr 06 22:19:45 PDT 2009\" included an un-recognized timezone \"PDT\". Dropping unrecognized timezones is deprecated; in a future version this will raise. Instead pass the string without the timezone, then use .tz_localize to convert to a recognized timezone.\n",
            "  df['date'] = pd.to_datetime(df['date'])\n"
          ]
        }
      ],
      "source": [
        "df['date'] = pd.to_datetime(df['date'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "neV79heaNRPR",
        "outputId": "f8c6ef8d-2f7a-445d-b7df-41b243862af1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>ids</th>\n",
              "      <th>date</th>\n",
              "      <th>flag</th>\n",
              "      <th>user</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810369</td>\n",
              "      <td>2009-04-06 22:19:45</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>_TheSpecialOne_</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810672</td>\n",
              "      <td>2009-04-06 22:19:49</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>scotthamilton</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810917</td>\n",
              "      <td>2009-04-06 22:19:53</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>mattycus</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811184</td>\n",
              "      <td>2009-04-06 22:19:57</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>ElleCTF</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811193</td>\n",
              "      <td>2009-04-06 22:19:57</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>Karoli</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   target         ids                date      flag             user  \\\n",
              "0       0  1467810369 2009-04-06 22:19:45  NO_QUERY  _TheSpecialOne_   \n",
              "1       0  1467810672 2009-04-06 22:19:49  NO_QUERY    scotthamilton   \n",
              "2       0  1467810917 2009-04-06 22:19:53  NO_QUERY         mattycus   \n",
              "3       0  1467811184 2009-04-06 22:19:57  NO_QUERY          ElleCTF   \n",
              "4       0  1467811193 2009-04-06 22:19:57  NO_QUERY           Karoli   \n",
              "\n",
              "                                                text  \n",
              "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
              "1  is upset that he can't update his Facebook by ...  \n",
              "2  @Kenichan I dived many times for the ball. Man...  \n",
              "3    my whole body feels itchy and like its on fire   \n",
              "4  @nationwideclass no, it's not behaving at all....  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZP3HoDFNZ57",
        "outputId": "89286b75-d804-4198-8c23-daf290ba149f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([2009])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['date'].dt.year.unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRQ89QENOsfY"
      },
      "source": [
        "Todos os tweets são datados de 2009"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8eGzFytNm9c",
        "outputId": "c91c0401-ecbe-4c9c-adf4-71529aeec35c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 4], dtype=int64)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['target'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyEZVjFmNxgH"
      },
      "source": [
        "TARGET: the polarity of the tweet (0 = negative, 2 = neutral, 4 = positive)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aX0HjnWlNt3Y",
        "outputId": "720f997a-ea28-4060-fcef-6f1a11776e89"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1600000, 6)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6g2tSOAOxzf"
      },
      "source": [
        "DF com 1.6M de linhas e 6 colunas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRYVG-ydO3yj"
      },
      "source": [
        "## Tratamento de Dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "la1qXH6FOwWR"
      },
      "outputs": [],
      "source": [
        "df_treat = df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "oTYjJQ82PC1h",
        "outputId": "1eb45154-f8bd-4546-90f2-97057bcde7f8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>ids</th>\n",
              "      <th>date</th>\n",
              "      <th>flag</th>\n",
              "      <th>user</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810369</td>\n",
              "      <td>2009-04-06 22:19:45</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>_TheSpecialOne_</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810672</td>\n",
              "      <td>2009-04-06 22:19:49</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>scotthamilton</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810917</td>\n",
              "      <td>2009-04-06 22:19:53</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>mattycus</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811184</td>\n",
              "      <td>2009-04-06 22:19:57</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>ElleCTF</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811193</td>\n",
              "      <td>2009-04-06 22:19:57</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>Karoli</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   target         ids                date      flag             user  \\\n",
              "0       0  1467810369 2009-04-06 22:19:45  NO_QUERY  _TheSpecialOne_   \n",
              "1       0  1467810672 2009-04-06 22:19:49  NO_QUERY    scotthamilton   \n",
              "2       0  1467810917 2009-04-06 22:19:53  NO_QUERY         mattycus   \n",
              "3       0  1467811184 2009-04-06 22:19:57  NO_QUERY          ElleCTF   \n",
              "4       0  1467811193 2009-04-06 22:19:57  NO_QUERY           Karoli   \n",
              "\n",
              "                                                text  \n",
              "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
              "1  is upset that he can't update his Facebook by ...  \n",
              "2  @Kenichan I dived many times for the ball. Man...  \n",
              "3    my whole body feels itchy and like its on fire   \n",
              "4  @nationwideclass no, it's not behaving at all....  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_treat.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "5glGc9hqPDlV"
      },
      "outputs": [],
      "source": [
        "df_treat.drop(['date', 'flag', 'user'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "B8PmHUtTPL39",
        "outputId": "91ed8bb6-8080-4a52-d25e-29704eba9e3e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>ids</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810369</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810672</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810917</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811184</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811193</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599995</th>\n",
              "      <td>4</td>\n",
              "      <td>2193601966</td>\n",
              "      <td>Just woke up. Having no school is the best fee...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599996</th>\n",
              "      <td>4</td>\n",
              "      <td>2193601969</td>\n",
              "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599997</th>\n",
              "      <td>4</td>\n",
              "      <td>2193601991</td>\n",
              "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599998</th>\n",
              "      <td>4</td>\n",
              "      <td>2193602064</td>\n",
              "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599999</th>\n",
              "      <td>4</td>\n",
              "      <td>2193602129</td>\n",
              "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1600000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         target         ids                                               text\n",
              "0             0  1467810369  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
              "1             0  1467810672  is upset that he can't update his Facebook by ...\n",
              "2             0  1467810917  @Kenichan I dived many times for the ball. Man...\n",
              "3             0  1467811184    my whole body feels itchy and like its on fire \n",
              "4             0  1467811193  @nationwideclass no, it's not behaving at all....\n",
              "...         ...         ...                                                ...\n",
              "1599995       4  2193601966  Just woke up. Having no school is the best fee...\n",
              "1599996       4  2193601969  TheWDB.com - Very cool to hear old Walt interv...\n",
              "1599997       4  2193601991  Are you ready for your MoJo Makeover? Ask me f...\n",
              "1599998       4  2193602064  Happy 38th Birthday to my boo of alll time!!! ...\n",
              "1599999       4  2193602129  happy #charitytuesday @theNSPCC @SparksCharity...\n",
              "\n",
              "[1600000 rows x 3 columns]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_treat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "df4 = df_treat[df_treat['target'] == 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>ids</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810369</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810672</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810917</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811184</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811193</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>799995</th>\n",
              "      <td>0</td>\n",
              "      <td>2329205009</td>\n",
              "      <td>Sick  Spending my day laying in bed listening ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>799996</th>\n",
              "      <td>0</td>\n",
              "      <td>2329205038</td>\n",
              "      <td>Gmail is down?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>799997</th>\n",
              "      <td>0</td>\n",
              "      <td>2329205473</td>\n",
              "      <td>rest in peace Farrah! So sad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>799998</th>\n",
              "      <td>0</td>\n",
              "      <td>2329205574</td>\n",
              "      <td>@Eric_Urbane Sounds like a rival is flagging y...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>799999</th>\n",
              "      <td>0</td>\n",
              "      <td>2329205794</td>\n",
              "      <td>has to resit exams over summer...  wishes he w...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>800000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        target         ids                                               text\n",
              "0            0  1467810369  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
              "1            0  1467810672  is upset that he can't update his Facebook by ...\n",
              "2            0  1467810917  @Kenichan I dived many times for the ball. Man...\n",
              "3            0  1467811184    my whole body feels itchy and like its on fire \n",
              "4            0  1467811193  @nationwideclass no, it's not behaving at all....\n",
              "...        ...         ...                                                ...\n",
              "799995       0  2329205009  Sick  Spending my day laying in bed listening ...\n",
              "799996       0  2329205038                                    Gmail is down? \n",
              "799997       0  2329205473                      rest in peace Farrah! So sad \n",
              "799998       0  2329205574  @Eric_Urbane Sounds like a rival is flagging y...\n",
              "799999       0  2329205794  has to resit exams over summer...  wishes he w...\n",
              "\n",
              "[800000 rows x 3 columns]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHfl7zznPMg-",
        "outputId": "c2fdac8c-ee93-4eec-eb9e-73c0b0325abf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5 tweets para podermos tratar os dados: \n",
            "\n",
            "Tweet 0 ->  @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D \n",
            "\n",
            "Tweet 1 ->  is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah! \n",
            "\n",
            "Tweet 2 ->  @Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds \n",
            "\n",
            "Tweet 3 ->  my whole body feels itchy and like its on fire  \n",
            "\n",
            "Tweet 4 ->  @nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there.  \n",
            "\n",
            "Tweet 5 ->  @Kwesidei not the whole crew  \n",
            "\n"
          ]
        }
      ],
      "source": [
        "print('5 tweets para podermos tratar os dados: \\n')\n",
        "\n",
        "for i in range(0,6):\n",
        "  print(f'Tweet {i} -> ', df_treat['text'][i], '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "fHPmjPaoPR0D"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "\n",
        "def data_treat(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "\n",
        "    # Remove mentions and hashtags\n",
        "    text = re.sub(r'@\\w+|#\\w+', '', text)\n",
        "\n",
        "    # Remove punctuation and special characters\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "\n",
        "    # Remove extra whitespaces\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    return text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "wsUNLBcMQTJH"
      },
      "outputs": [],
      "source": [
        "dft = df[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46pYO837QWHK",
        "outputId": "ca374461-cdff-405e-de11-d06b73eadf09"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Lucas\\AppData\\Local\\Temp\\ipykernel_19776\\944507329.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  dft['text'] = dft['text'].apply(data_treat)\n"
          ]
        }
      ],
      "source": [
        "# Testando função\n",
        "\n",
        "dft['text'] = dft['text'].apply(data_treat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "rnHWGZi_QXU8",
        "outputId": "055e6190-6f00-4b3d-cf1d-55142181ed0f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>ids</th>\n",
              "      <th>date</th>\n",
              "      <th>flag</th>\n",
              "      <th>user</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810369</td>\n",
              "      <td>2009-04-06 22:19:45</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>_TheSpecialOne_</td>\n",
              "      <td>a thats a bummer you shoulda got david carr of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810672</td>\n",
              "      <td>2009-04-06 22:19:49</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>scotthamilton</td>\n",
              "      <td>is upset that he cant update his facebook by t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810917</td>\n",
              "      <td>2009-04-06 22:19:53</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>mattycus</td>\n",
              "      <td>i dived many times for the ball managed to sav...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811184</td>\n",
              "      <td>2009-04-06 22:19:57</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>ElleCTF</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811193</td>\n",
              "      <td>2009-04-06 22:19:57</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>Karoli</td>\n",
              "      <td>no its not behaving at all im mad why am i her...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   target         ids                date      flag             user  \\\n",
              "0       0  1467810369 2009-04-06 22:19:45  NO_QUERY  _TheSpecialOne_   \n",
              "1       0  1467810672 2009-04-06 22:19:49  NO_QUERY    scotthamilton   \n",
              "2       0  1467810917 2009-04-06 22:19:53  NO_QUERY         mattycus   \n",
              "3       0  1467811184 2009-04-06 22:19:57  NO_QUERY          ElleCTF   \n",
              "4       0  1467811193 2009-04-06 22:19:57  NO_QUERY           Karoli   \n",
              "\n",
              "                                                text  \n",
              "0  a thats a bummer you shoulda got david carr of...  \n",
              "1  is upset that he cant update his facebook by t...  \n",
              "2  i dived many times for the ball managed to sav...  \n",
              "3     my whole body feels itchy and like its on fire  \n",
              "4  no its not behaving at all im mad why am i her...  "
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dft.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "OkRcygEvQ8qt"
      },
      "outputs": [],
      "source": [
        "df_treat['text'] = df_treat['text'].apply(data_treat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Ulgp6sYORk7r",
        "outputId": "cb93f0f3-c7e2-40f4-d854-61d47738e0eb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>ids</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810369</td>\n",
              "      <td>a thats a bummer you shoulda got david carr of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810672</td>\n",
              "      <td>is upset that he cant update his facebook by t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810917</td>\n",
              "      <td>i dived many times for the ball managed to sav...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811184</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811193</td>\n",
              "      <td>no its not behaving at all im mad why am i her...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599995</th>\n",
              "      <td>4</td>\n",
              "      <td>2193601966</td>\n",
              "      <td>just woke up having no school is the best feel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599996</th>\n",
              "      <td>4</td>\n",
              "      <td>2193601969</td>\n",
              "      <td>thewdbcom very cool to hear old walt interviews â</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599997</th>\n",
              "      <td>4</td>\n",
              "      <td>2193601991</td>\n",
              "      <td>are you ready for your mojo makeover ask me fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599998</th>\n",
              "      <td>4</td>\n",
              "      <td>2193602064</td>\n",
              "      <td>happy 38th birthday to my boo of alll time tup...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599999</th>\n",
              "      <td>4</td>\n",
              "      <td>2193602129</td>\n",
              "      <td>happy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1600000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         target         ids                                               text\n",
              "0             0  1467810369  a thats a bummer you shoulda got david carr of...\n",
              "1             0  1467810672  is upset that he cant update his facebook by t...\n",
              "2             0  1467810917  i dived many times for the ball managed to sav...\n",
              "3             0  1467811184     my whole body feels itchy and like its on fire\n",
              "4             0  1467811193  no its not behaving at all im mad why am i her...\n",
              "...         ...         ...                                                ...\n",
              "1599995       4  2193601966  just woke up having no school is the best feel...\n",
              "1599996       4  2193601969  thewdbcom very cool to hear old walt interviews â\n",
              "1599997       4  2193601991  are you ready for your mojo makeover ask me fo...\n",
              "1599998       4  2193602064  happy 38th birthday to my boo of alll time tup...\n",
              "1599999       4  2193602129                                              happy\n",
              "\n",
              "[1600000 rows x 3 columns]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_treat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tamanho do treino: (100000, 3), Tamanho do teste: (50000, 3)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Selecionar 150.000 amostras do dataset original\n",
        "df_subset = df_treat.sample(n=150000, random_state=42)\n",
        "\n",
        "# Embaralhar e dividir o subset em treino e teste\n",
        "train_df, test_df = train_test_split(df_subset, test_size=50000, shuffle=True, random_state=42)\n",
        "\n",
        "train_df = train_df.reset_index(drop=True)\n",
        "test_df = test_df.reset_index(drop=True)\n",
        "\n",
        "# Verificar as dimensões\n",
        "print(f\"Tamanho do treino: {train_df.shape}, Tamanho do teste: {test_df.shape}\")\n",
        "\n",
        "# Agora, você pode continuar com a criação dos embeddings e DataLoaders\n",
        "train_embeddings = train_df['text'].values  # Pegando os embeddings de treino\n",
        "test_embeddings = test_df['text'].values  # Pegando os embeddings de teste\n",
        "\n",
        "# Codificando os alvos para valores inteiros\n",
        "le = LabelEncoder()\n",
        "\n",
        "train_embeddingsy = le.fit_transform(train_df['target'])  # Codificando as classes de treino\n",
        "test_embeddingsy = le.transform(test_df['target'])  # Codificando as classes de teste"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Começando treinamento do Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_path = \"ibm-granite/granite-embedding-278m-multilingual\"\n",
        "# Load the Sentence Transformer model\n",
        "model = SentenceTransformer(model_path)\n",
        "\n",
        "# encode queries and passages\n",
        "train_embeddings = model.encode(train_embeddings)\n",
        "\n",
        "test_embeddings = model.encode(test_embeddings)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X shape: torch.Size([64, 768]), y shape: torch.Size([64])\n",
            "X shape: torch.Size([64, 768]), y shape: torch.Size([64])\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "\n",
        "# Certifique-se de que os dados estão no dispositivo certo\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Criando Dataset e DataLoader para os dados de teste\n",
        "X_test = torch.tensor(test_embeddings, dtype=torch.float32).to(device)\n",
        "y_test = torch.tensor(test_embeddingsy, dtype=torch.long).to(device)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Testar iteração dos dados de teste\n",
        "for X, y in test_dataloader:\n",
        "    print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n",
        "    break  # Apenas para verificar um batch\n",
        "\n",
        "# Criando Dataset e DataLoader para os dados de treino\n",
        "X_train = torch.tensor(train_embeddings, dtype=torch.float32).to(device)\n",
        "y_train = torch.tensor(train_embeddingsy, dtype=torch.long).to(device)\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Testar iteração dos dados de treino\n",
        "for X, y in train_dataloader:\n",
        "    print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n",
        "    break  # Apenas para verificar um batch\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0, 1, 1,  ..., 1, 0, 0], device='cuda:0')"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NeuralNetwork(\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=2, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Definição do modelo SYA3\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()  # Chama o construtor da classe pai (nn.Module)\n",
        "\n",
        "        # Pilha de camadas lineares com funções de ativação ReLU\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(768, 512),  # Camada totalmente conectada de entrada (768 -> 512 neurônios)\n",
        "            nn.ReLU(),  # Função de ativação ReLU para introduzir não linearidade\n",
        "            nn.Linear(512, 512),  # Segunda camada oculta (512 -> 512 neurônios)\n",
        "            nn.ReLU(),  # Ativação ReLU novamente\n",
        "            nn.Linear(512, 2),  # Camada de saída (512 -> 10 neurônios, supondo 2 classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Define a passagem para frente (forward pass) do modelo\"\"\"\n",
        "        logits = self.linear_relu_stack(x)  # Passa os dados pela pilha de camadas\n",
        "        return logits  # Retorna os logits (valores brutos antes da ativação softmax)\n",
        "\n",
        "# Verifica se há uma GPU disponível e define o dispositivo adequado (GPU ou CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Instancia o modelo e o move para o dispositivo correto (GPU se disponível, senão CPU)\n",
        "SentimentAnalysis_Model = NeuralNetwork().to(device)\n",
        "\n",
        "# Exibe a arquitetura do modelo\n",
        "print(SentimentAnalysis_Model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**O que é a ReLU?**\n",
        "\n",
        "A ReLU (Rectified Linear Unit) é uma função de ativação amplamente usada em redes neurais. Ela é responsável por introduzir não linearidade no modelo, permitindo que ele aprenda padrões mais complexos.\n",
        "\n",
        "A fórmula da ReLU é simples:\n",
        "\n",
        "    ReLU(x) = max(0, x)\n",
        "\n",
        "Ou seja:\n",
        "\n",
        "    Se o valor de entrada x for positivo, a saída será x.\n",
        "    Se o valor de entrada x for negativo, a saída será 0.\n",
        "\n",
        "**Por que usar a ReLU?**\n",
        "\n",
        "    Simples e eficiente: A ReLU é muito simples de calcular, o que ajuda a tornar o treinamento mais rápido.\n",
        "    Evita o problema do gradiente desvanecido: Quando você usa funções como sigmoid ou tanh, elas podem \"saturar\" (ficar muito próximas de 0 ou 1), fazendo com que o gradiente durante o treinamento diminua muito (desvanecimento do gradiente). A ReLU resolve esse problema, pois para valores positivos, ela retorna uma inclinação constante.\n",
        "    Efetiva em muitas tarefas: A ReLU tem sido usada com sucesso em uma vasta gama de modelos de deep learning.\n",
        "\n",
        "Exemplo:\n",
        "\n",
        "Se tivermos uma entrada x = -2, a ReLU retorna 0. Se a entrada for x = 3, a saída será 3.\n",
        "\n",
        "**O que é \"não linearidade\" e por que é importante?**\n",
        "\n",
        "Não linearidade é a capacidade de um modelo aprender relações complexas entre as entradas e saídas.\n",
        "Se usássemos apenas operações lineares (por exemplo, multiplicações e somas), o modelo seria equivalente a uma única transformação linear, não importando quantas camadas tivéssemos. Isso limitaria sua capacidade de modelar padrões complexos.\n",
        "\n",
        "    Ao aplicar funções de ativação não lineares, como a ReLU, o modelo pode combinar essas transformações lineares de forma a capturar relações complexas.\n",
        "    Exemplo: Imagine que você precisa modelar uma relação curva entre variáveis. Uma simples combinação linear não consegue representar essa curva. Com funções não lineares, o modelo pode aprender essa curvatura e outros padrões complexos presentes nos dados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(SentimentAnalysis_Model.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "**Função de Perda**\n",
        "\n",
        "A função de perda é uma função matemática que mede o erro do modelo durante o treinamento. O objetivo do treinamento é minimizar esse erro, ou seja, fazer com que o modelo preveja o mais próximo possível da verdade real.\n",
        "\n",
        "No seu caso, você está usando a função de perda CrossEntropyLoss.\n",
        "\n",
        "CrossEntropyLoss é usada em problemas de classificação, onde o modelo precisa escolher entre várias classes possíveis (por exemplo, identificar qual é a imagem de um gato, cachorro, etc.).\n",
        "\n",
        "A função CrossEntropyLoss compara as probabilidades previstas pelo modelo com as probabilidades reais e calcula um valor de erro. Quanto menor o valor da perda, melhor o modelo está se saindo.\n",
        "Como a CrossEntropyLoss funciona:\n",
        "\n",
        "    O modelo gera uma probabilidade para cada classe. Se temos 3 classes, o modelo pode prever algo como: [0.2, 0.7, 0.1].\n",
        "    Se a classe real for a classe 2 (index 1), a CrossEntropyLoss vai penalizar o modelo mais fortemente quanto menor for a probabilidade atribuída à classe correta.\n",
        "\n",
        "**Otimizador**\n",
        "\n",
        "O otimizador é o componente que ajusta os pesos do modelo para reduzir a função de perda. Ele basicamente determina como os parâmetros do modelo (os pesos das conexões entre os neurônios) devem ser atualizados para reduzir o erro.\n",
        "\n",
        "Aqui estamos usando o SGD (Stochastic Gradient Descent) como otimizador.\n",
        "\n",
        "O que é o SGD?\n",
        "\n",
        "O SGD é uma versão do gradiente descendente onde a atualização dos pesos é feita com base em apenas um exemplo (ou poucos exemplos) de cada vez, ao invés de usar todos os exemplos no conjunto de dados. Isso torna o processo de otimização mais rápido, embora possa ser um pouco mais ruidoso.\n",
        "Como o SGD funciona:\n",
        "\n",
        "    Calcula o Gradiente: O SGD calcula a direção do gradiente da função de perda em relação aos parâmetros do modelo (como os pesos). O gradiente indica em que direção devemos ajustar os parâmetros para reduzir a perda.\n",
        "    Atualiza os Pesos: O SGD usa a direção do gradiente para atualizar os parâmetros. A atualização é feita com base em uma taxa chamada taxa de aprendizado (learning rate).\n",
        "        Se a taxa de aprendizado for alta, os pesos serão ajustados em grandes passos.\n",
        "        Se for baixa, o ajuste será mais sutil.\n",
        "\n",
        "A fórmula para o gradiente descendente simples é:\n",
        "\n",
        "    w = w - lr * gradiente, onde:\n",
        "        w são os pesos do modelo,\n",
        "        lr é a taxa de aprendizado,\n",
        "        gradiente é a derivada da função de perda em relação aos pesos.\n",
        "\n",
        "Parâmetros do Otimizador:\n",
        "\n",
        "    model.parameters(): Passa todos os parâmetros do modelo (os pesos e vieses dos neurônios) para o otimizador, para que ele possa atualizá-los durante o treinamento.\n",
        "    lr=1e-3: A taxa de aprendizado, que controla o tamanho dos passos dados durante a atualização dos pesos. 1e-3 é o mesmo que 0.001. Se a taxa de aprendizado for muito alta, o modelo pode \"pular\" a solução ótima. Se for muito baixa, o treinamento será mais demorado.\n",
        "\n",
        "Resumo:\n",
        "\n",
        "    Função de Perda (como CrossEntropyLoss) mede o erro entre as previsões do modelo e as classes reais. O objetivo é minimizar essa perda.\n",
        "    Otimizador (como SGD) atualiza os pesos do modelo para reduzir a perda, ajustando-os com base no gradiente da função de perda.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset) # Calcula o tamanho do dataset de treino\n",
        "    model.train() # Treina o modelo\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error -> Preve o resultado e calcula  função de perda\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation -> Otimizador usa a função de perda para ajustar o modelo e ao mesmo tempo minimizar a função de perda\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), (batch + 1) * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset) # Calcula o tamanho do dataset de teste\n",
        "    num_batches = len(dataloader) # Calcula a quantidade de batchs (quantidade de dados que serão processados por vez)\n",
        "    model.eval() # Avaliação do modelo\n",
        "    test_loss, correct = 0, 0  # Inicializa as variáveis para armazenar a perda total (test_loss) e o número de acertos (correct) com zero\n",
        "    with torch.no_grad():  # Desativa o cálculo de gradientes para economizar memória e tempo de computação\n",
        "        for X, y in dataloader:  # Itera sobre o DataLoader, que fornece batches de dados de entrada (X) e rótulos reais (y)\n",
        "            X, y = X.to(device), y.to(device)  # Move os dados e rótulos para o dispositivo (CPU ou GPU)\n",
        "            pred = model(X)  # Faz uma previsão usando o modelo com os dados de entrada X\n",
        "            test_loss += loss_fn(pred, y).item()  # Calcula a perda entre a previsão e o rótulo real, adicionando ao total da perda\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()  # Conta as previsões corretas (compara a classe com maior probabilidade)\n",
        "    test_loss /= num_batches  # Calcula a média da perda no conjunto de teste\n",
        "    correct /= size  # Calcula a acurácia dividindo o número de acertos pelo total de amostras\n",
        "\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "\n",
            "Training: \n",
            "\n",
            "loss: 0.691761  [   64/100000]\n",
            "loss: 0.690514  [ 6464/100000]\n",
            "loss: 0.694211  [12864/100000]\n",
            "loss: 0.689152  [19264/100000]\n",
            "loss: 0.693704  [25664/100000]\n",
            "loss: 0.692391  [32064/100000]\n",
            "loss: 0.689284  [38464/100000]\n",
            "loss: 0.693021  [44864/100000]\n",
            "loss: 0.691416  [51264/100000]\n",
            "loss: 0.693556  [57664/100000]\n",
            "loss: 0.693695  [64064/100000]\n",
            "loss: 0.693706  [70464/100000]\n",
            "loss: 0.691678  [76864/100000]\n",
            "loss: 0.692293  [83264/100000]\n",
            "loss: 0.692623  [89664/100000]\n",
            "loss: 0.691928  [96064/100000]\n",
            "\n",
            "Testing: \n",
            "\n",
            "Test Error: \n",
            " Accuracy: 50.2%, Avg loss: 0.692970 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "\n",
            "Training: \n",
            "\n",
            "loss: 0.693437  [   64/100000]\n",
            "loss: 0.693887  [ 6464/100000]\n",
            "loss: 0.691819  [12864/100000]\n",
            "loss: 0.695604  [19264/100000]\n",
            "loss: 0.693179  [25664/100000]\n",
            "loss: 0.692986  [32064/100000]\n",
            "loss: 0.693434  [38464/100000]\n",
            "loss: 0.693924  [44864/100000]\n",
            "loss: 0.692936  [51264/100000]\n",
            "loss: 0.693187  [57664/100000]\n",
            "loss: 0.691977  [64064/100000]\n",
            "loss: 0.692867  [70464/100000]\n",
            "loss: 0.693176  [76864/100000]\n",
            "loss: 0.693456  [83264/100000]\n",
            "loss: 0.692852  [89664/100000]\n",
            "loss: 0.692274  [96064/100000]\n",
            "\n",
            "Testing: \n",
            "\n",
            "Test Error: \n",
            " Accuracy: 51.7%, Avg loss: 0.692795 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "\n",
            "Training: \n",
            "\n",
            "loss: 0.692318  [   64/100000]\n",
            "loss: 0.692417  [ 6464/100000]\n",
            "loss: 0.693205  [12864/100000]\n",
            "loss: 0.692429  [19264/100000]\n",
            "loss: 0.692412  [25664/100000]\n",
            "loss: 0.693464  [32064/100000]\n",
            "loss: 0.692860  [38464/100000]\n",
            "loss: 0.692899  [44864/100000]\n",
            "loss: 0.692286  [51264/100000]\n",
            "loss: 0.692911  [57664/100000]\n",
            "loss: 0.692552  [64064/100000]\n",
            "loss: 0.693003  [70464/100000]\n",
            "loss: 0.691955  [76864/100000]\n",
            "loss: 0.692621  [83264/100000]\n",
            "loss: 0.693059  [89664/100000]\n",
            "loss: 0.693194  [96064/100000]\n",
            "\n",
            "Testing: \n",
            "\n",
            "Test Error: \n",
            " Accuracy: 53.8%, Avg loss: 0.692627 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "\n",
            "Training: \n",
            "\n",
            "loss: 0.693547  [   64/100000]\n",
            "loss: 0.692346  [ 6464/100000]\n",
            "loss: 0.692991  [12864/100000]\n",
            "loss: 0.692636  [19264/100000]\n",
            "loss: 0.692246  [25664/100000]\n",
            "loss: 0.692560  [32064/100000]\n",
            "loss: 0.693038  [38464/100000]\n",
            "loss: 0.692786  [44864/100000]\n",
            "loss: 0.691955  [51264/100000]\n",
            "loss: 0.692516  [57664/100000]\n",
            "loss: 0.692966  [64064/100000]\n",
            "loss: 0.692498  [70464/100000]\n",
            "loss: 0.693079  [76864/100000]\n",
            "loss: 0.691841  [83264/100000]\n",
            "loss: 0.691782  [89664/100000]\n",
            "loss: 0.693184  [96064/100000]\n",
            "\n",
            "Testing: \n",
            "\n",
            "Test Error: \n",
            " Accuracy: 55.6%, Avg loss: 0.692456 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "\n",
            "Training: \n",
            "\n",
            "loss: 0.692585  [   64/100000]\n",
            "loss: 0.692186  [ 6464/100000]\n",
            "loss: 0.692790  [12864/100000]\n",
            "loss: 0.692579  [19264/100000]\n",
            "loss: 0.693034  [25664/100000]\n",
            "loss: 0.691985  [32064/100000]\n",
            "loss: 0.692631  [38464/100000]\n",
            "loss: 0.691786  [44864/100000]\n",
            "loss: 0.691996  [51264/100000]\n",
            "loss: 0.693709  [57664/100000]\n",
            "loss: 0.691997  [64064/100000]\n",
            "loss: 0.692574  [70464/100000]\n",
            "loss: 0.692790  [76864/100000]\n",
            "loss: 0.691873  [83264/100000]\n",
            "loss: 0.692536  [89664/100000]\n",
            "loss: 0.692177  [96064/100000]\n",
            "\n",
            "Testing: \n",
            "\n",
            "Test Error: \n",
            " Accuracy: 61.0%, Avg loss: 0.692282 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "\n",
            "Training: \n",
            "\n",
            "loss: 0.692401  [   64/100000]\n",
            "loss: 0.691987  [ 6464/100000]\n",
            "loss: 0.692567  [12864/100000]\n",
            "loss: 0.692933  [19264/100000]\n",
            "loss: 0.693038  [25664/100000]\n",
            "loss: 0.692278  [32064/100000]\n",
            "loss: 0.691425  [38464/100000]\n",
            "loss: 0.692237  [44864/100000]\n",
            "loss: 0.692382  [51264/100000]\n",
            "loss: 0.692288  [57664/100000]\n",
            "loss: 0.692258  [64064/100000]\n",
            "loss: 0.692050  [70464/100000]\n",
            "loss: 0.692116  [76864/100000]\n",
            "loss: 0.692613  [83264/100000]\n",
            "loss: 0.692448  [89664/100000]\n",
            "loss: 0.692083  [96064/100000]\n",
            "\n",
            "Testing: \n",
            "\n",
            "Test Error: \n",
            " Accuracy: 61.0%, Avg loss: 0.692099 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "\n",
            "Training: \n",
            "\n",
            "loss: 0.691967  [   64/100000]\n",
            "loss: 0.691799  [ 6464/100000]\n",
            "loss: 0.692601  [12864/100000]\n",
            "loss: 0.691846  [19264/100000]\n",
            "loss: 0.691471  [25664/100000]\n",
            "loss: 0.692068  [32064/100000]\n",
            "loss: 0.692190  [38464/100000]\n",
            "loss: 0.691574  [44864/100000]\n",
            "loss: 0.692266  [51264/100000]\n",
            "loss: 0.692333  [57664/100000]\n",
            "loss: 0.691882  [64064/100000]\n",
            "loss: 0.691515  [70464/100000]\n",
            "loss: 0.692500  [76864/100000]\n",
            "loss: 0.692315  [83264/100000]\n",
            "loss: 0.691955  [89664/100000]\n",
            "loss: 0.692750  [96064/100000]\n",
            "\n",
            "Testing: \n",
            "\n",
            "Test Error: \n",
            " Accuracy: 64.2%, Avg loss: 0.691905 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "\n",
            "Training: \n",
            "\n",
            "loss: 0.691682  [   64/100000]\n",
            "loss: 0.691615  [ 6464/100000]\n",
            "loss: 0.692122  [12864/100000]\n",
            "loss: 0.691568  [19264/100000]\n",
            "loss: 0.691931  [25664/100000]\n",
            "loss: 0.692217  [32064/100000]\n",
            "loss: 0.690983  [38464/100000]\n",
            "loss: 0.692128  [44864/100000]\n",
            "loss: 0.691147  [51264/100000]\n",
            "loss: 0.692596  [57664/100000]\n",
            "loss: 0.692233  [64064/100000]\n",
            "loss: 0.691459  [70464/100000]\n",
            "loss: 0.691854  [76864/100000]\n",
            "loss: 0.692068  [83264/100000]\n",
            "loss: 0.692210  [89664/100000]\n",
            "loss: 0.691434  [96064/100000]\n",
            "\n",
            "Testing: \n",
            "\n",
            "Test Error: \n",
            " Accuracy: 68.4%, Avg loss: 0.691700 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "\n",
            "Training: \n",
            "\n",
            "loss: 0.691748  [   64/100000]\n",
            "loss: 0.691457  [ 6464/100000]\n",
            "loss: 0.691928  [12864/100000]\n",
            "loss: 0.692147  [19264/100000]\n",
            "loss: 0.691304  [25664/100000]\n",
            "loss: 0.692261  [32064/100000]\n",
            "loss: 0.692082  [38464/100000]\n",
            "loss: 0.691323  [44864/100000]\n",
            "loss: 0.691309  [51264/100000]\n",
            "loss: 0.691709  [57664/100000]\n",
            "loss: 0.691302  [64064/100000]\n",
            "loss: 0.691507  [70464/100000]\n",
            "loss: 0.691691  [76864/100000]\n",
            "loss: 0.691895  [83264/100000]\n",
            "loss: 0.691606  [89664/100000]\n",
            "loss: 0.691979  [96064/100000]\n",
            "\n",
            "Testing: \n",
            "\n",
            "Test Error: \n",
            " Accuracy: 70.9%, Avg loss: 0.691481 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "\n",
            "Training: \n",
            "\n",
            "loss: 0.691511  [   64/100000]\n",
            "loss: 0.690834  [ 6464/100000]\n",
            "loss: 0.691369  [12864/100000]\n",
            "loss: 0.691778  [19264/100000]\n",
            "loss: 0.690824  [25664/100000]\n",
            "loss: 0.690979  [32064/100000]\n",
            "loss: 0.691838  [38464/100000]\n",
            "loss: 0.691027  [44864/100000]\n",
            "loss: 0.690514  [51264/100000]\n",
            "loss: 0.691953  [57664/100000]\n",
            "loss: 0.690874  [64064/100000]\n",
            "loss: 0.691533  [70464/100000]\n",
            "loss: 0.691582  [76864/100000]\n",
            "loss: 0.690710  [83264/100000]\n",
            "loss: 0.690799  [89664/100000]\n",
            "loss: 0.690838  [96064/100000]\n",
            "\n",
            "Testing: \n",
            "\n",
            "Test Error: \n",
            " Accuracy: 70.1%, Avg loss: 0.691239 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "\n",
            "Training: \n",
            "\n",
            "loss: 0.691225  [   64/100000]\n",
            "loss: 0.691792  [ 6464/100000]\n",
            "loss: 0.691169  [12864/100000]\n",
            "loss: 0.691178  [19264/100000]\n",
            "loss: 0.690680  [25664/100000]\n",
            "loss: 0.690209  [32064/100000]\n",
            "loss: 0.691260  [38464/100000]\n",
            "loss: 0.691576  [44864/100000]\n",
            "loss: 0.690955  [51264/100000]\n",
            "loss: 0.691953  [57664/100000]\n",
            "loss: 0.691496  [64064/100000]\n",
            "loss: 0.690918  [70464/100000]\n",
            "loss: 0.691694  [76864/100000]\n",
            "loss: 0.690279  [83264/100000]\n",
            "loss: 0.691336  [89664/100000]\n",
            "loss: 0.690749  [96064/100000]\n",
            "\n",
            "Testing: \n",
            "\n",
            "Test Error: \n",
            " Accuracy: 69.6%, Avg loss: 0.690979 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "\n",
            "Training: \n",
            "\n",
            "loss: 0.692312  [   64/100000]\n",
            "loss: 0.690148  [ 6464/100000]\n",
            "loss: 0.690776  [12864/100000]\n",
            "loss: 0.690395  [19264/100000]\n",
            "loss: 0.691700  [25664/100000]\n",
            "loss: 0.691258  [32064/100000]\n",
            "loss: 0.690469  [38464/100000]\n",
            "loss: 0.691289  [44864/100000]\n",
            "loss: 0.690955  [51264/100000]\n",
            "loss: 0.691944  [57664/100000]\n",
            "loss: 0.691511  [64064/100000]\n",
            "loss: 0.692180  [70464/100000]\n",
            "loss: 0.689840  [76864/100000]\n",
            "loss: 0.690488  [83264/100000]\n",
            "loss: 0.690020  [89664/100000]\n",
            "loss: 0.690575  [96064/100000]\n",
            "\n",
            "Testing: \n",
            "\n",
            "Test Error: \n",
            " Accuracy: 71.8%, Avg loss: 0.690706 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "\n",
            "Training: \n",
            "\n",
            "loss: 0.689792  [   64/100000]\n",
            "loss: 0.690971  [ 6464/100000]\n",
            "loss: 0.690885  [12864/100000]\n",
            "loss: 0.690932  [19264/100000]\n",
            "loss: 0.690760  [25664/100000]\n",
            "loss: 0.690897  [32064/100000]\n",
            "loss: 0.691500  [38464/100000]\n",
            "loss: 0.691044  [44864/100000]\n",
            "loss: 0.690484  [51264/100000]\n",
            "loss: 0.690820  [57664/100000]\n",
            "loss: 0.690591  [64064/100000]\n",
            "loss: 0.690815  [70464/100000]\n",
            "loss: 0.689614  [76864/100000]\n",
            "loss: 0.689146  [83264/100000]\n",
            "loss: 0.690904  [89664/100000]\n",
            "loss: 0.691218  [96064/100000]\n",
            "\n",
            "Testing: \n",
            "\n",
            "Test Error: \n",
            " Accuracy: 72.3%, Avg loss: 0.690401 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "\n",
            "Training: \n",
            "\n",
            "loss: 0.690680  [   64/100000]\n",
            "loss: 0.690778  [ 6464/100000]\n",
            "loss: 0.690894  [12864/100000]\n",
            "loss: 0.689875  [19264/100000]\n",
            "loss: 0.690044  [25664/100000]\n",
            "loss: 0.689923  [32064/100000]\n",
            "loss: 0.690331  [38464/100000]\n",
            "loss: 0.690126  [44864/100000]\n",
            "loss: 0.689239  [51264/100000]\n",
            "loss: 0.689650  [57664/100000]\n",
            "loss: 0.690999  [64064/100000]\n",
            "loss: 0.689800  [70464/100000]\n",
            "loss: 0.691118  [76864/100000]\n",
            "loss: 0.689373  [83264/100000]\n",
            "loss: 0.689733  [89664/100000]\n",
            "loss: 0.691043  [96064/100000]\n",
            "\n",
            "Testing: \n",
            "\n",
            "Test Error: \n",
            " Accuracy: 70.9%, Avg loss: 0.690065 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "\n",
            "Training: \n",
            "\n",
            "loss: 0.690034  [   64/100000]\n",
            "loss: 0.688704  [ 6464/100000]\n",
            "loss: 0.689506  [12864/100000]\n",
            "loss: 0.689733  [19264/100000]\n",
            "loss: 0.690772  [25664/100000]\n",
            "loss: 0.689809  [32064/100000]\n",
            "loss: 0.690522  [38464/100000]\n",
            "loss: 0.689359  [44864/100000]\n",
            "loss: 0.690038  [51264/100000]\n",
            "loss: 0.690716  [57664/100000]\n",
            "loss: 0.689584  [64064/100000]\n",
            "loss: 0.690043  [70464/100000]\n",
            "loss: 0.690025  [76864/100000]\n",
            "loss: 0.689287  [83264/100000]\n",
            "loss: 0.690075  [89664/100000]\n",
            "loss: 0.689457  [96064/100000]\n",
            "\n",
            "Testing: \n",
            "\n",
            "Test Error: \n",
            " Accuracy: 72.5%, Avg loss: 0.689701 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "\n",
            "Training: \n",
            "\n",
            "loss: 0.690566  [   64/100000]\n",
            "loss: 0.690786  [ 6464/100000]\n",
            "loss: 0.689231  [12864/100000]\n",
            "loss: 0.690676  [19264/100000]\n",
            "loss: 0.689734  [25664/100000]\n",
            "loss: 0.690374  [32064/100000]\n",
            "loss: 0.689848  [38464/100000]\n",
            "loss: 0.689052  [44864/100000]\n",
            "loss: 0.689617  [51264/100000]\n",
            "loss: 0.688682  [57664/100000]\n",
            "loss: 0.690320  [64064/100000]\n",
            "loss: 0.689661  [70464/100000]\n",
            "loss: 0.688598  [76864/100000]\n",
            "loss: 0.688549  [83264/100000]\n",
            "loss: 0.689898  [89664/100000]\n",
            "loss: 0.689493  [96064/100000]\n",
            "\n",
            "Testing: \n",
            "\n",
            "Test Error: \n",
            " Accuracy: 72.4%, Avg loss: 0.689293 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "\n",
            "Training: \n",
            "\n",
            "loss: 0.688925  [   64/100000]\n",
            "loss: 0.688965  [ 6464/100000]\n",
            "loss: 0.688983  [12864/100000]\n",
            "loss: 0.687934  [19264/100000]\n",
            "loss: 0.689795  [25664/100000]\n",
            "loss: 0.690274  [32064/100000]\n",
            "loss: 0.690278  [38464/100000]\n",
            "loss: 0.688649  [44864/100000]\n",
            "loss: 0.690001  [51264/100000]\n",
            "loss: 0.689864  [57664/100000]\n",
            "loss: 0.689172  [64064/100000]\n",
            "loss: 0.690800  [70464/100000]\n",
            "loss: 0.688519  [76864/100000]\n",
            "loss: 0.689961  [83264/100000]\n",
            "loss: 0.688274  [89664/100000]\n",
            "loss: 0.688562  [96064/100000]\n",
            "\n",
            "Testing: \n",
            "\n",
            "Test Error: \n",
            " Accuracy: 72.2%, Avg loss: 0.688837 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "\n",
            "Training: \n",
            "\n",
            "loss: 0.689181  [   64/100000]\n",
            "loss: 0.688332  [ 6464/100000]\n",
            "loss: 0.688537  [12864/100000]\n",
            "loss: 0.689110  [19264/100000]\n",
            "loss: 0.688678  [25664/100000]\n",
            "loss: 0.690293  [32064/100000]\n",
            "loss: 0.688245  [38464/100000]\n",
            "loss: 0.690018  [44864/100000]\n",
            "loss: 0.688534  [51264/100000]\n",
            "loss: 0.689116  [57664/100000]\n",
            "loss: 0.688523  [64064/100000]\n",
            "loss: 0.688763  [70464/100000]\n",
            "loss: 0.690478  [76864/100000]\n",
            "loss: 0.689324  [83264/100000]\n",
            "loss: 0.687822  [89664/100000]\n",
            "loss: 0.689960  [96064/100000]\n",
            "\n",
            "Testing: \n",
            "\n",
            "Test Error: \n",
            " Accuracy: 71.2%, Avg loss: 0.688325 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "\n",
            "Training: \n",
            "\n",
            "loss: 0.688204  [   64/100000]\n",
            "loss: 0.687272  [ 6464/100000]\n",
            "loss: 0.687488  [12864/100000]\n",
            "loss: 0.689706  [19264/100000]\n",
            "loss: 0.688628  [25664/100000]\n",
            "loss: 0.686993  [32064/100000]\n",
            "loss: 0.686933  [38464/100000]\n",
            "loss: 0.688402  [44864/100000]\n",
            "loss: 0.688401  [51264/100000]\n",
            "loss: 0.687810  [57664/100000]\n",
            "loss: 0.686374  [64064/100000]\n",
            "loss: 0.687288  [70464/100000]\n",
            "loss: 0.685399  [76864/100000]\n",
            "loss: 0.688653  [83264/100000]\n",
            "loss: 0.686439  [89664/100000]\n",
            "loss: 0.687186  [96064/100000]\n",
            "\n",
            "Testing: \n",
            "\n",
            "Test Error: \n",
            " Accuracy: 72.9%, Avg loss: 0.687750 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "\n",
            "Training: \n",
            "\n",
            "loss: 0.688290  [   64/100000]\n",
            "loss: 0.688837  [ 6464/100000]\n",
            "loss: 0.688480  [12864/100000]\n",
            "loss: 0.687628  [19264/100000]\n",
            "loss: 0.685199  [25664/100000]\n",
            "loss: 0.687216  [32064/100000]\n",
            "loss: 0.687343  [38464/100000]\n",
            "loss: 0.688680  [44864/100000]\n",
            "loss: 0.687558  [51264/100000]\n",
            "loss: 0.687480  [57664/100000]\n",
            "loss: 0.685457  [64064/100000]\n",
            "loss: 0.686140  [70464/100000]\n",
            "loss: 0.687008  [76864/100000]\n",
            "loss: 0.687571  [83264/100000]\n",
            "loss: 0.687080  [89664/100000]\n",
            "loss: 0.688597  [96064/100000]\n",
            "\n",
            "Testing: \n",
            "\n",
            "Test Error: \n",
            " Accuracy: 73.0%, Avg loss: 0.687096 \n",
            "\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "epochs = 20\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    print(f'\\nTraining: \\n')\n",
        "    train(train_dataloader, SentimentAnalysis_Model, loss_fn, optimizer)\n",
        "    print(f'\\nTesting: \\n')\n",
        "\n",
        "    test(test_dataloader, SentimentAnalysis_Model, loss_fn)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Texto: I  hate MY LIFE EVERYDAY\n",
            "Texto negativo\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def programa(texto):\n",
        "    # Carregar o modelo de embeddings (SentenceTransformer)\n",
        "\n",
        "    # Cria uma lista com o texto a ser processado\n",
        "    novos_textos = [texto]\n",
        "\n",
        "    # Gera os embeddings dos textos (retorna um numpy array)\n",
        "    novos_embeddings = model.encode(novos_textos)\n",
        "\n",
        "    # Converte os embeddings para tensor e os move para o dispositivo\n",
        "    novos_embeddings_tensor = torch.tensor(novos_embeddings, dtype=torch.float32).to(device)\n",
        "\n",
        "    # Coloca o modelo de classificação em modo de avaliação\n",
        "    SentimentAnalysis_Model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Passa os embeddings pelo modelo de classificação\n",
        "        outputs = SentimentAnalysis_Model(novos_embeddings_tensor)\n",
        "        # Se o modelo é de classificação, obtenha a classe prevista\n",
        "        _, predicted_classes = torch.max(outputs, dim=1)\n",
        "        predicted_label = le.inverse_transform(predicted_classes.cpu().numpy())\n",
        "\n",
        "    print(f\"Texto: {texto}\")\n",
        "    #print(f\"Embeddings gerados: {novos_embeddings_tensor}\")\n",
        "    if predicted_label == 4:\n",
        "        \n",
        "       #print(f\"Classe prevista: {predicted_label.item()}\")\n",
        "       print(f'Texto positivo!')\n",
        "    else:\n",
        "        print(f'Texto negativo')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Texto: I love my life\n",
            "Texto positivo!\n"
          ]
        }
      ],
      "source": [
        "text = input('Escreva sua mensagem: ')\n",
        "programa(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved PyTorch Model State to model.pth\n"
          ]
        }
      ],
      "source": [
        "torch.save(SentimentAnalysis_Model.state_dict(), \"SentimentAnalysis_Model.pth\")\n",
        "print(\"Saved PyTorch Model State to model.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
